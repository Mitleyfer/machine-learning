{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.8 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is already saved in the Workspace and can be accessed at the file path provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "env = UnityEnvironment(file_name=\"/data/Tennis_Linux_NoVis/Tennis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -6.65278625 -1.5        -0.          0.\n",
      "  6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: 0.04500000085681677\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):                                         # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1 DDPG Algorithm**\n",
    "\n",
    "According to https://towardsdatascience.com/deep-deterministic-policy-gradient-ddpg-theory-and-implementation-747a3010e82f:\n",
    "\n",
    "Deep Deterministic Policy Gradient (DDPG) is a reinforcement learning technique that combines both Q-learning and Policy gradients. DDPG being an actor-critic technique consists of two models: Actor and Critic. The actor is a policy network that takes the state as input and outputs the exact action (continuous), instead of a probability distribution over actions. The critic is a Q-value network that takes in state and action as input and outputs the Q-value. DDPG is an “off”-policy method. DDPG is used in the continuous action setting and the “deterministic” in DDPG refers to the fact that the actor computes the action directly instead of a probability distribution over actions. DDPG is used in a continuous action setting and is an improvement over the vanilla actor-critic.\n",
    "\n",
    "**4.2 Neural Networks architecture**\n",
    "\n",
    "The Actor and Critic are sharing the same architecture, consist of two fully-connected layers with Batch normalization applied to second hidden layer. ReLu has been used as activation function for hidden layers and Tanh for output. The weights defined from uniform distribution.\n",
    "\n",
    "**4.3 Hyperparameters**\n",
    "\n",
    "Hyperparameters from learning exercises has been used as a starting point. Then hyperparameters were improved empirically.\n",
    "\n",
    "- fc1_units=512 # Number of nodes in the first hidden layer\n",
    "- fc2_units=512 # Number of nodes in the second hidden layer\n",
    "- BUFFER_SIZE = int(1e6) # replay buffer size\n",
    "- BATCH_SIZE = 256 # minibatch size\n",
    "- GAMMA = 0.99 # discount factor\n",
    "- TAU = 1e-3 # for soft update of target parameters\n",
    "- LR_ACTOR = 1e-3 # learning rate of the actor\n",
    "- LR_CRITIC = 1e-3 # learning rate of the critic\n",
    "- WEIGHT_DECAY = 0 # L2 weight decay\n",
    "- LEARN_EVERY = 1 # learning timestep interval\n",
    "- LEARN_NUM = 10 # number of learning passes\n",
    "- GRAD_CLIPPING = 1.0 # gradient clipping\n",
    "- OU_SIGMA = 0.2 # OU noise parameter\n",
    "- OU_THETA = 0.15 # OU noise parameter\n",
    "- EPSILON = 1.0 # for epsilon in the noise process (act step)\n",
    "- EPSILON_DECAY = 1e-6 3 epsilon decay rate\n",
    "- num_episodes=10000 # maximum number of training episodes\n",
    "- max_t=1000 # maximum number of timesteps per episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return(-lim, lim)\n",
    "\n",
    "def linear(fc_in, fc_out, batch_norm = True):\n",
    "    layers = []\n",
    "    linear_layer = nn.Linear(fc_in, fc_out)\n",
    "    layers.append(linear_layer)\n",
    "    if batch_norm:\n",
    "        layers.append(nn.BatchNorm1d(fc_out))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=512, fc2_units=512):\n",
    "        \n",
    "        super(Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = linear(state_size, fc1_units, batch_norm = False)\n",
    "        self.fc2 = linear(fc1_units, fc2_units)\n",
    "        self.fc3 =  linear(fc2_units, action_size, batch_norm = False)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1[0].weight.data.uniform_(*hidden_init(self.fc1[0]))\n",
    "        self.fc2[0].weight.data.uniform_(*hidden_init(self.fc2[0]))\n",
    "        self.fc3[0].weight.data.uniform_(-3e-3, 3e-3)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.tanh(self.fc3(x))\n",
    "    \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=512, fc2_units=512):\n",
    "        super(Critic, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = linear(state_size, fc1_units, batch_norm = False)\n",
    "        self.fc2 = linear(fc1_units+action_size, fc2_units)\n",
    "        self.fc3 = linear(fc2_units, 1, batch_norm = False)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1[0].weight.data.uniform_(*hidden_init(self.fc1[0]))\n",
    "        self.fc2[0].weight.data.uniform_(*hidden_init(self.fc2[0]))\n",
    "        self.fc3[0].weight.data.uniform_(-3e-3, 3e-3)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = torch.cat((x, action), dim=1)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "BUFFER_SIZE = int(1e6) \n",
    "BATCH_SIZE = 256       \n",
    "GAMMA = 0.99           \n",
    "TAU = 2e-3             \n",
    "LR_ACTOR = 1e-3        \n",
    "LR_CRITIC = 1e-3       \n",
    "WEIGHT_DECAY = 0       \n",
    "\n",
    "LEARN_EVERY = 1       \n",
    "LEARN_NUM = 10           \n",
    "GRAD_CLIPPING = 1.0         \n",
    "\n",
    "OU_SIGMA = 0.1\n",
    "OU_THETA = 0.15\n",
    "\n",
    "EPSILON = 1.0         \n",
    "EPSILON_DECAY = 1e-6\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Agent():\n",
    "    \n",
    "    def __init__(self, state_size, action_size, random_seed=0):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(random_seed)\n",
    "        \n",
    "        self.epsilon = EPSILON\n",
    "        \n",
    "        self.actor_local = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_target = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=LR_ACTOR)\n",
    "        \n",
    "        self.critic_local = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_target = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=LR_CRITIC, weight_decay=WEIGHT_DECAY)\n",
    "        \n",
    "        self.noise = OUNoise(action_size, random_seed)\n",
    "        \n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, random_seed)\n",
    "        \n",
    "        \n",
    "    def step(self, state, action, reward, next_state, done, timestep):\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        if len(self.memory) > BATCH_SIZE and timestep % LEARN_EVERY == 0:\n",
    "            for _ in range(LEARN_NUM):\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, GAMMA)\n",
    "                \n",
    "    def act(self, state, add_noise=True):\n",
    "        state = torch.from_numpy(state).float().to(device)\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_local(state).cpu().data.numpy()\n",
    "        self.actor_local.train()\n",
    "        \n",
    "        if add_noise:\n",
    "            action += self.epsilon * self.noise.sample()\n",
    "            \n",
    "        return np.clip(action, -1, 1)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.noise.reset()\n",
    "        \n",
    "    def learn(self, experiences, gamma):\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "        \n",
    "        actions_next = self.actor_target(next_states)\n",
    "        Q_targets_next = self.critic_target(next_states, actions_next)\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "        Q_expected = self.critic_local(states, actions)\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        if GRAD_CLIPPING > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(self.critic_local.parameters(), GRAD_CLIPPING)\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        actions_pred = self.actor_local(states)\n",
    "        actor_loss = -self.critic_local(states, actions_pred).mean()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "        \n",
    "        self.soft_update(self.critic_local, self.critic_target, TAU)\n",
    "        self.soft_update(self.actor_local, self.actor_target, TAU)\n",
    "        \n",
    "        if EPSILON_DECAY > 0:\n",
    "            self.epsilon -= EPSILON_DECAY\n",
    "            self.noise.reset()\n",
    "            \n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "            \n",
    "class OUNoise:\n",
    "    \n",
    "    def __init__(self, size, seed, mu=0., theta=OU_THETA, sigma=OU_SIGMA):\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.seed = random.seed(seed)\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.state = copy.copy(self.mu)\n",
    "        \n",
    "    def sample(self):\n",
    "        x = self.state\n",
    "        self.state = x + np.random.normal(self.mu, self.sigma)\n",
    "        return self.state\n",
    "    \n",
    "class ReplayBuffer:\n",
    "       \n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size) \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names = [\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "        \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "        \n",
    "    def sample(self):\n",
    "        experiences =  random.sample(self.memory, k=self.batch_size)\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "        \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg(num_episodes=10000, max_t=1000, print_every=1):\n",
    "    \n",
    "    max_scores = [] \n",
    "    running_avgs = []\n",
    "    best_score = -np.inf\n",
    "    scores_mean = deque(maxlen=100) \n",
    "    \n",
    "    for i_episode in range(1, num_episodes + 1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name] \n",
    "        states = env_info.vector_observations \n",
    "        scores = np.zeros(num_agents) \n",
    "        agent.reset()\n",
    "        for t in range(max_t):\n",
    "            actions = agent.act(states, add_noise=True) \n",
    "            env_info = env.step(actions)[brain_name]  \n",
    "            next_states = env_info.vector_observations \n",
    "            rewards = env_info.rewards \n",
    "            dones = env_info.local_done \n",
    "            for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "                agent.step(state, action, reward, next_state, done, t)\n",
    "            states = next_states\n",
    "            scores += rewards\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        max_scores.append(np.max(scores)) \n",
    "        scores_mean.append(max_scores[-1]) \n",
    "        running_avgs.append(np.mean(scores_mean)) \n",
    "        \n",
    "        if i_episode % print_every == 0:\n",
    "            print(\"\\rEpisode {} \\tMax score: {:.5f}\\tMoving Avg: {:.5f}\"\\\n",
    "                  .format(i_episode, max_scores[-1], running_avgs[-1]))\n",
    "        if running_avgs[-1] >= 0.5:\n",
    "            print(\"\\nEnvironment solved in {:d} episodes.\\tAverage score: {:.3f}\"\\\n",
    "                 .format(i_episode, running_avgs[-1]))\n",
    "            torch.save(agent.actor_local.state_dict(), 'actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'critic.pth')\n",
    "            break\n",
    "            \n",
    "    return max_scores, running_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3\n",
    "agent = Agent(state_size=state_size, action_size=action_size, random_seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 \tMax score: 0.00000\tMoving Avg: 0.00000\n",
      "Episode 2 \tMax score: 0.00000\tMoving Avg: 0.00000\n",
      "Episode 3 \tMax score: 0.00000\tMoving Avg: 0.00000\n",
      "Episode 4 \tMax score: 0.00000\tMoving Avg: 0.00000\n",
      "Episode 5 \tMax score: 0.00000\tMoving Avg: 0.00000\n",
      "Episode 6 \tMax score: 0.00000\tMoving Avg: 0.00000\n",
      "Episode 7 \tMax score: 0.00000\tMoving Avg: 0.00000\n",
      "Episode 8 \tMax score: 0.00000\tMoving Avg: 0.00000\n",
      "Episode 9 \tMax score: 0.00000\tMoving Avg: 0.00000\n",
      "Episode 10 \tMax score: 0.09000\tMoving Avg: 0.00900\n",
      "Episode 11 \tMax score: 0.00000\tMoving Avg: 0.00818\n",
      "Episode 12 \tMax score: 0.00000\tMoving Avg: 0.00750\n",
      "Episode 13 \tMax score: 0.10000\tMoving Avg: 0.01462\n",
      "Episode 14 \tMax score: 0.00000\tMoving Avg: 0.01357\n",
      "Episode 15 \tMax score: 0.00000\tMoving Avg: 0.01267\n",
      "Episode 16 \tMax score: 0.00000\tMoving Avg: 0.01188\n",
      "Episode 17 \tMax score: 0.00000\tMoving Avg: 0.01118\n",
      "Episode 18 \tMax score: 0.00000\tMoving Avg: 0.01056\n",
      "Episode 19 \tMax score: 0.00000\tMoving Avg: 0.01000\n",
      "Episode 20 \tMax score: 0.00000\tMoving Avg: 0.00950\n",
      "Episode 21 \tMax score: 0.00000\tMoving Avg: 0.00905\n",
      "Episode 22 \tMax score: 0.00000\tMoving Avg: 0.00864\n",
      "Episode 23 \tMax score: 0.00000\tMoving Avg: 0.00826\n",
      "Episode 24 \tMax score: 0.00000\tMoving Avg: 0.00792\n",
      "Episode 25 \tMax score: 0.00000\tMoving Avg: 0.00760\n",
      "Episode 26 \tMax score: 0.00000\tMoving Avg: 0.00731\n",
      "Episode 27 \tMax score: 0.00000\tMoving Avg: 0.00704\n",
      "Episode 28 \tMax score: 0.00000\tMoving Avg: 0.00679\n",
      "Episode 29 \tMax score: 0.00000\tMoving Avg: 0.00655\n",
      "Episode 30 \tMax score: 0.00000\tMoving Avg: 0.00633\n",
      "Episode 31 \tMax score: 0.00000\tMoving Avg: 0.00613\n",
      "Episode 32 \tMax score: 0.00000\tMoving Avg: 0.00594\n",
      "Episode 33 \tMax score: 0.00000\tMoving Avg: 0.00576\n",
      "Episode 34 \tMax score: 0.00000\tMoving Avg: 0.00559\n",
      "Episode 35 \tMax score: 0.09000\tMoving Avg: 0.00800\n",
      "Episode 36 \tMax score: 0.10000\tMoving Avg: 0.01056\n",
      "Episode 37 \tMax score: 0.10000\tMoving Avg: 0.01297\n",
      "Episode 38 \tMax score: 0.00000\tMoving Avg: 0.01263\n",
      "Episode 39 \tMax score: 0.00000\tMoving Avg: 0.01231\n",
      "Episode 40 \tMax score: 0.10000\tMoving Avg: 0.01450\n",
      "Episode 41 \tMax score: 0.00000\tMoving Avg: 0.01415\n",
      "Episode 42 \tMax score: 0.10000\tMoving Avg: 0.01619\n",
      "Episode 43 \tMax score: 0.09000\tMoving Avg: 0.01791\n",
      "Episode 44 \tMax score: 0.00000\tMoving Avg: 0.01750\n",
      "Episode 45 \tMax score: 0.00000\tMoving Avg: 0.01711\n",
      "Episode 46 \tMax score: 0.09000\tMoving Avg: 0.01870\n",
      "Episode 47 \tMax score: 0.09000\tMoving Avg: 0.02021\n",
      "Episode 48 \tMax score: 0.00000\tMoving Avg: 0.01979\n",
      "Episode 49 \tMax score: 0.09000\tMoving Avg: 0.02122\n",
      "Episode 50 \tMax score: 0.00000\tMoving Avg: 0.02080\n",
      "Episode 51 \tMax score: 0.09000\tMoving Avg: 0.02216\n",
      "Episode 52 \tMax score: 0.10000\tMoving Avg: 0.02365\n",
      "Episode 53 \tMax score: 0.10000\tMoving Avg: 0.02509\n",
      "Episode 54 \tMax score: 0.10000\tMoving Avg: 0.02648\n",
      "Episode 55 \tMax score: 0.09000\tMoving Avg: 0.02764\n",
      "Episode 56 \tMax score: 0.10000\tMoving Avg: 0.02893\n",
      "Episode 57 \tMax score: 0.10000\tMoving Avg: 0.03018\n",
      "Episode 58 \tMax score: 0.20000\tMoving Avg: 0.03310\n",
      "Episode 59 \tMax score: 0.10000\tMoving Avg: 0.03424\n",
      "Episode 60 \tMax score: 0.10000\tMoving Avg: 0.03533\n",
      "Episode 61 \tMax score: 0.10000\tMoving Avg: 0.03639\n",
      "Episode 62 \tMax score: 0.10000\tMoving Avg: 0.03742\n",
      "Episode 63 \tMax score: 0.00000\tMoving Avg: 0.03683\n",
      "Episode 64 \tMax score: 0.10000\tMoving Avg: 0.03781\n",
      "Episode 65 \tMax score: 0.10000\tMoving Avg: 0.03877\n",
      "Episode 66 \tMax score: 0.10000\tMoving Avg: 0.03970\n",
      "Episode 67 \tMax score: 0.10000\tMoving Avg: 0.04060\n",
      "Episode 68 \tMax score: 0.20000\tMoving Avg: 0.04294\n",
      "Episode 69 \tMax score: 0.10000\tMoving Avg: 0.04377\n",
      "Episode 70 \tMax score: 0.10000\tMoving Avg: 0.04457\n",
      "Episode 71 \tMax score: 0.10000\tMoving Avg: 0.04535\n",
      "Episode 72 \tMax score: 0.10000\tMoving Avg: 0.04611\n",
      "Episode 73 \tMax score: 0.00000\tMoving Avg: 0.04548\n",
      "Episode 74 \tMax score: 0.00000\tMoving Avg: 0.04486\n",
      "Episode 75 \tMax score: 0.00000\tMoving Avg: 0.04427\n",
      "Episode 76 \tMax score: 0.00000\tMoving Avg: 0.04368\n",
      "Episode 77 \tMax score: 0.00000\tMoving Avg: 0.04312\n",
      "Episode 78 \tMax score: 0.00000\tMoving Avg: 0.04256\n",
      "Episode 79 \tMax score: 0.00000\tMoving Avg: 0.04203\n",
      "Episode 80 \tMax score: 0.10000\tMoving Avg: 0.04275\n",
      "Episode 81 \tMax score: 0.10000\tMoving Avg: 0.04346\n",
      "Episode 82 \tMax score: 0.00000\tMoving Avg: 0.04293\n",
      "Episode 83 \tMax score: 0.10000\tMoving Avg: 0.04361\n",
      "Episode 84 \tMax score: 0.10000\tMoving Avg: 0.04429\n",
      "Episode 85 \tMax score: 0.09000\tMoving Avg: 0.04482\n",
      "Episode 86 \tMax score: 0.09000\tMoving Avg: 0.04535\n",
      "Episode 87 \tMax score: 0.00000\tMoving Avg: 0.04483\n",
      "Episode 88 \tMax score: 0.20000\tMoving Avg: 0.04659\n",
      "Episode 89 \tMax score: 0.10000\tMoving Avg: 0.04719\n",
      "Episode 90 \tMax score: 0.10000\tMoving Avg: 0.04778\n",
      "Episode 91 \tMax score: 0.10000\tMoving Avg: 0.04835\n",
      "Episode 92 \tMax score: 0.10000\tMoving Avg: 0.04891\n",
      "Episode 93 \tMax score: 0.10000\tMoving Avg: 0.04946\n",
      "Episode 94 \tMax score: 0.10000\tMoving Avg: 0.05000\n",
      "Episode 95 \tMax score: 0.00000\tMoving Avg: 0.04947\n",
      "Episode 96 \tMax score: 0.00000\tMoving Avg: 0.04896\n",
      "Episode 97 \tMax score: 0.20000\tMoving Avg: 0.05052\n",
      "Episode 98 \tMax score: 0.00000\tMoving Avg: 0.05000\n",
      "Episode 99 \tMax score: 0.00000\tMoving Avg: 0.04949\n",
      "Episode 100 \tMax score: 0.00000\tMoving Avg: 0.04900\n",
      "Episode 101 \tMax score: 0.00000\tMoving Avg: 0.04900\n",
      "Episode 102 \tMax score: 0.00000\tMoving Avg: 0.04900\n",
      "Episode 103 \tMax score: 0.10000\tMoving Avg: 0.05000\n",
      "Episode 104 \tMax score: 0.09000\tMoving Avg: 0.05090\n",
      "Episode 105 \tMax score: 0.00000\tMoving Avg: 0.05090\n",
      "Episode 106 \tMax score: 0.09000\tMoving Avg: 0.05180\n",
      "Episode 107 \tMax score: 0.10000\tMoving Avg: 0.05280\n",
      "Episode 108 \tMax score: 0.10000\tMoving Avg: 0.05380\n",
      "Episode 109 \tMax score: 0.20000\tMoving Avg: 0.05580\n",
      "Episode 110 \tMax score: 0.09000\tMoving Avg: 0.05580\n",
      "Episode 111 \tMax score: 0.10000\tMoving Avg: 0.05680\n",
      "Episode 112 \tMax score: 0.00000\tMoving Avg: 0.05680\n",
      "Episode 113 \tMax score: 0.10000\tMoving Avg: 0.05680\n",
      "Episode 114 \tMax score: 0.09000\tMoving Avg: 0.05770\n",
      "Episode 115 \tMax score: 0.09000\tMoving Avg: 0.05860\n",
      "Episode 116 \tMax score: 0.20000\tMoving Avg: 0.06060\n",
      "Episode 117 \tMax score: 0.20000\tMoving Avg: 0.06260\n",
      "Episode 118 \tMax score: 0.20000\tMoving Avg: 0.06460\n",
      "Episode 119 \tMax score: 0.10000\tMoving Avg: 0.06560\n",
      "Episode 120 \tMax score: 0.10000\tMoving Avg: 0.06660\n",
      "Episode 121 \tMax score: 0.00000\tMoving Avg: 0.06660\n",
      "Episode 122 \tMax score: 0.00000\tMoving Avg: 0.06660\n",
      "Episode 123 \tMax score: 0.10000\tMoving Avg: 0.06760\n",
      "Episode 124 \tMax score: 0.10000\tMoving Avg: 0.06860\n",
      "Episode 125 \tMax score: 0.09000\tMoving Avg: 0.06950\n",
      "Episode 126 \tMax score: 0.10000\tMoving Avg: 0.07050\n",
      "Episode 127 \tMax score: 0.10000\tMoving Avg: 0.07150\n",
      "Episode 128 \tMax score: 0.20000\tMoving Avg: 0.07350\n",
      "Episode 129 \tMax score: 0.19000\tMoving Avg: 0.07540\n",
      "Episode 130 \tMax score: 0.10000\tMoving Avg: 0.07640\n",
      "Episode 131 \tMax score: 0.10000\tMoving Avg: 0.07740\n",
      "Episode 132 \tMax score: 0.00000\tMoving Avg: 0.07740\n",
      "Episode 133 \tMax score: 0.10000\tMoving Avg: 0.07840\n",
      "Episode 134 \tMax score: 0.10000\tMoving Avg: 0.07940\n",
      "Episode 135 \tMax score: 0.10000\tMoving Avg: 0.07950\n",
      "Episode 136 \tMax score: 0.10000\tMoving Avg: 0.07950\n",
      "Episode 137 \tMax score: 0.10000\tMoving Avg: 0.07950\n",
      "Episode 138 \tMax score: 0.20000\tMoving Avg: 0.08150\n",
      "Episode 139 \tMax score: 0.10000\tMoving Avg: 0.08250\n",
      "Episode 140 \tMax score: 0.10000\tMoving Avg: 0.08250\n",
      "Episode 141 \tMax score: 0.10000\tMoving Avg: 0.08350\n",
      "Episode 142 \tMax score: 0.20000\tMoving Avg: 0.08450\n",
      "Episode 143 \tMax score: 0.30000\tMoving Avg: 0.08660\n",
      "Episode 144 \tMax score: 0.00000\tMoving Avg: 0.08660\n",
      "Episode 145 \tMax score: 0.00000\tMoving Avg: 0.08660\n",
      "Episode 146 \tMax score: 0.10000\tMoving Avg: 0.08670\n",
      "Episode 147 \tMax score: 0.20000\tMoving Avg: 0.08780\n",
      "Episode 148 \tMax score: 0.20000\tMoving Avg: 0.08980\n",
      "Episode 149 \tMax score: 0.00000\tMoving Avg: 0.08890\n",
      "Episode 150 \tMax score: 0.00000\tMoving Avg: 0.08890\n",
      "Episode 151 \tMax score: 0.10000\tMoving Avg: 0.08900\n",
      "Episode 152 \tMax score: 0.70000\tMoving Avg: 0.09500\n",
      "Episode 153 \tMax score: 0.00000\tMoving Avg: 0.09400\n",
      "Episode 154 \tMax score: 0.10000\tMoving Avg: 0.09400\n",
      "Episode 155 \tMax score: 0.00000\tMoving Avg: 0.09310\n",
      "Episode 156 \tMax score: 0.10000\tMoving Avg: 0.09310\n",
      "Episode 157 \tMax score: 0.10000\tMoving Avg: 0.09310\n",
      "Episode 158 \tMax score: 0.10000\tMoving Avg: 0.09210\n",
      "Episode 159 \tMax score: 0.00000\tMoving Avg: 0.09110\n",
      "Episode 160 \tMax score: 0.20000\tMoving Avg: 0.09210\n",
      "Episode 161 \tMax score: 0.20000\tMoving Avg: 0.09310\n",
      "Episode 162 \tMax score: 0.10000\tMoving Avg: 0.09310\n",
      "Episode 163 \tMax score: 0.10000\tMoving Avg: 0.09410\n",
      "Episode 164 \tMax score: 0.10000\tMoving Avg: 0.09410\n",
      "Episode 165 \tMax score: 0.10000\tMoving Avg: 0.09410\n",
      "Episode 166 \tMax score: 0.20000\tMoving Avg: 0.09510\n",
      "Episode 167 \tMax score: 0.09000\tMoving Avg: 0.09500\n",
      "Episode 168 \tMax score: 0.10000\tMoving Avg: 0.09400\n",
      "Episode 169 \tMax score: 0.30000\tMoving Avg: 0.09600\n",
      "Episode 170 \tMax score: 0.20000\tMoving Avg: 0.09700\n",
      "Episode 171 \tMax score: 0.10000\tMoving Avg: 0.09700\n",
      "Episode 172 \tMax score: 0.10000\tMoving Avg: 0.09700\n",
      "Episode 173 \tMax score: 0.20000\tMoving Avg: 0.09900\n",
      "Episode 174 \tMax score: 0.00000\tMoving Avg: 0.09900\n",
      "Episode 175 \tMax score: 0.10000\tMoving Avg: 0.10000\n",
      "Episode 176 \tMax score: 0.10000\tMoving Avg: 0.10100\n",
      "Episode 177 \tMax score: 0.19000\tMoving Avg: 0.10290\n",
      "Episode 178 \tMax score: 0.00000\tMoving Avg: 0.10290\n",
      "Episode 179 \tMax score: 0.10000\tMoving Avg: 0.10390\n",
      "Episode 180 \tMax score: 0.10000\tMoving Avg: 0.10390\n",
      "Episode 181 \tMax score: 0.10000\tMoving Avg: 0.10390\n",
      "Episode 182 \tMax score: 0.30000\tMoving Avg: 0.10690\n",
      "Episode 183 \tMax score: 0.20000\tMoving Avg: 0.10790\n",
      "Episode 184 \tMax score: 0.09000\tMoving Avg: 0.10780\n",
      "Episode 185 \tMax score: 0.10000\tMoving Avg: 0.10790\n",
      "Episode 186 \tMax score: 0.19000\tMoving Avg: 0.10890\n",
      "Episode 187 \tMax score: 0.20000\tMoving Avg: 0.11090\n",
      "Episode 188 \tMax score: 0.10000\tMoving Avg: 0.10990\n",
      "Episode 189 \tMax score: 0.10000\tMoving Avg: 0.10990\n",
      "Episode 190 \tMax score: 0.20000\tMoving Avg: 0.11090\n",
      "Episode 191 \tMax score: 0.00000\tMoving Avg: 0.10990\n",
      "Episode 192 \tMax score: 0.19000\tMoving Avg: 0.11080\n",
      "Episode 193 \tMax score: 0.20000\tMoving Avg: 0.11180\n",
      "Episode 194 \tMax score: 0.20000\tMoving Avg: 0.11280\n",
      "Episode 195 \tMax score: 0.40000\tMoving Avg: 0.11680\n",
      "Episode 196 \tMax score: 0.10000\tMoving Avg: 0.11780\n",
      "Episode 197 \tMax score: 0.30000\tMoving Avg: 0.11880\n",
      "Episode 198 \tMax score: 0.10000\tMoving Avg: 0.11980\n",
      "Episode 199 \tMax score: 0.10000\tMoving Avg: 0.12080\n",
      "Episode 200 \tMax score: 0.00000\tMoving Avg: 0.12080\n",
      "Episode 201 \tMax score: 0.10000\tMoving Avg: 0.12180\n",
      "Episode 202 \tMax score: 0.10000\tMoving Avg: 0.12280\n",
      "Episode 203 \tMax score: 0.10000\tMoving Avg: 0.12280\n",
      "Episode 204 \tMax score: 0.09000\tMoving Avg: 0.12280\n",
      "Episode 205 \tMax score: 0.49000\tMoving Avg: 0.12770\n",
      "Episode 206 \tMax score: 0.20000\tMoving Avg: 0.12880\n",
      "Episode 207 \tMax score: 0.39000\tMoving Avg: 0.13170\n",
      "Episode 208 \tMax score: 0.00000\tMoving Avg: 0.13070\n",
      "Episode 209 \tMax score: 0.30000\tMoving Avg: 0.13170\n",
      "Episode 210 \tMax score: 0.10000\tMoving Avg: 0.13180\n",
      "Episode 211 \tMax score: 0.20000\tMoving Avg: 0.13280\n",
      "Episode 212 \tMax score: 0.20000\tMoving Avg: 0.13480\n",
      "Episode 213 \tMax score: 0.20000\tMoving Avg: 0.13580\n",
      "Episode 214 \tMax score: 0.30000\tMoving Avg: 0.13790\n",
      "Episode 215 \tMax score: 0.10000\tMoving Avg: 0.13800\n",
      "Episode 216 \tMax score: 0.10000\tMoving Avg: 0.13700\n",
      "Episode 217 \tMax score: 0.30000\tMoving Avg: 0.13800\n",
      "Episode 218 \tMax score: 0.00000\tMoving Avg: 0.13600\n",
      "Episode 219 \tMax score: 0.10000\tMoving Avg: 0.13600\n",
      "Episode 220 \tMax score: 0.10000\tMoving Avg: 0.13600\n",
      "Episode 221 \tMax score: 0.10000\tMoving Avg: 0.13700\n",
      "Episode 222 \tMax score: 0.20000\tMoving Avg: 0.13900\n",
      "Episode 223 \tMax score: 0.20000\tMoving Avg: 0.14000\n",
      "Episode 224 \tMax score: 0.90000\tMoving Avg: 0.14800\n",
      "Episode 225 \tMax score: 0.30000\tMoving Avg: 0.15010\n",
      "Episode 226 \tMax score: 0.30000\tMoving Avg: 0.15210\n",
      "Episode 227 \tMax score: 0.20000\tMoving Avg: 0.15310\n",
      "Episode 228 \tMax score: 0.09000\tMoving Avg: 0.15200\n",
      "Episode 229 \tMax score: 0.40000\tMoving Avg: 0.15410\n",
      "Episode 230 \tMax score: 0.30000\tMoving Avg: 0.15610\n",
      "Episode 231 \tMax score: 0.20000\tMoving Avg: 0.15710\n",
      "Episode 232 \tMax score: 0.10000\tMoving Avg: 0.15810\n",
      "Episode 233 \tMax score: 0.10000\tMoving Avg: 0.15810\n",
      "Episode 234 \tMax score: 0.10000\tMoving Avg: 0.15810\n",
      "Episode 235 \tMax score: 0.40000\tMoving Avg: 0.16110\n",
      "Episode 236 \tMax score: 0.09000\tMoving Avg: 0.16100\n",
      "Episode 237 \tMax score: 0.10000\tMoving Avg: 0.16100\n",
      "Episode 238 \tMax score: 0.10000\tMoving Avg: 0.16000\n",
      "Episode 239 \tMax score: 0.40000\tMoving Avg: 0.16300\n",
      "Episode 240 \tMax score: 0.30000\tMoving Avg: 0.16500\n",
      "Episode 241 \tMax score: 0.30000\tMoving Avg: 0.16700\n",
      "Episode 242 \tMax score: 0.20000\tMoving Avg: 0.16700\n",
      "Episode 243 \tMax score: 0.10000\tMoving Avg: 0.16500\n",
      "Episode 244 \tMax score: 0.30000\tMoving Avg: 0.16800\n",
      "Episode 245 \tMax score: 0.40000\tMoving Avg: 0.17200\n",
      "Episode 246 \tMax score: 0.40000\tMoving Avg: 0.17500\n",
      "Episode 247 \tMax score: 0.10000\tMoving Avg: 0.17400\n",
      "Episode 248 \tMax score: 0.50000\tMoving Avg: 0.17700\n",
      "Episode 249 \tMax score: 0.10000\tMoving Avg: 0.17800\n",
      "Episode 250 \tMax score: 0.20000\tMoving Avg: 0.18000\n",
      "Episode 251 \tMax score: 0.10000\tMoving Avg: 0.18000\n",
      "Episode 252 \tMax score: 0.20000\tMoving Avg: 0.17500\n",
      "Episode 253 \tMax score: 0.00000\tMoving Avg: 0.17500\n",
      "Episode 254 \tMax score: 0.10000\tMoving Avg: 0.17500\n",
      "Episode 256 \tMax score: 0.20000\tMoving Avg: 0.17800\n",
      "Episode 257 \tMax score: 0.60000\tMoving Avg: 0.18300\n",
      "Episode 258 \tMax score: 0.10000\tMoving Avg: 0.18300\n",
      "Episode 259 \tMax score: 0.40000\tMoving Avg: 0.18700\n",
      "Episode 260 \tMax score: 0.20000\tMoving Avg: 0.18700\n",
      "Episode 261 \tMax score: 0.20000\tMoving Avg: 0.18700\n",
      "Episode 262 \tMax score: 0.10000\tMoving Avg: 0.18700\n",
      "Episode 263 \tMax score: 0.30000\tMoving Avg: 0.18900\n",
      "Episode 264 \tMax score: 0.20000\tMoving Avg: 0.19000\n",
      "Episode 265 \tMax score: 0.60000\tMoving Avg: 0.19500\n",
      "Episode 266 \tMax score: 0.10000\tMoving Avg: 0.19400\n",
      "Episode 267 \tMax score: 0.60000\tMoving Avg: 0.19910\n",
      "Episode 268 \tMax score: 0.59000\tMoving Avg: 0.20400\n",
      "Episode 269 \tMax score: 0.20000\tMoving Avg: 0.20300\n",
      "Episode 270 \tMax score: 0.10000\tMoving Avg: 0.20200\n",
      "Episode 271 \tMax score: 0.50000\tMoving Avg: 0.20600\n",
      "Episode 272 \tMax score: 0.40000\tMoving Avg: 0.20900\n",
      "Episode 273 \tMax score: 0.10000\tMoving Avg: 0.20800\n",
      "Episode 274 \tMax score: 0.10000\tMoving Avg: 0.20900\n",
      "Episode 275 \tMax score: 0.39000\tMoving Avg: 0.21190\n",
      "Episode 276 \tMax score: 0.10000\tMoving Avg: 0.21190\n",
      "Episode 277 \tMax score: 0.90000\tMoving Avg: 0.21900\n",
      "Episode 278 \tMax score: 0.30000\tMoving Avg: 0.22200\n",
      "Episode 279 \tMax score: 0.50000\tMoving Avg: 0.22600\n",
      "Episode 280 \tMax score: 0.20000\tMoving Avg: 0.22700\n",
      "Episode 281 \tMax score: 0.10000\tMoving Avg: 0.22700\n",
      "Episode 282 \tMax score: 0.00000\tMoving Avg: 0.22400\n",
      "Episode 283 \tMax score: 0.70000\tMoving Avg: 0.22900\n",
      "Episode 284 \tMax score: 0.20000\tMoving Avg: 0.23010\n",
      "Episode 285 \tMax score: 0.40000\tMoving Avg: 0.23310\n",
      "Episode 286 \tMax score: 0.30000\tMoving Avg: 0.23420\n",
      "Episode 287 \tMax score: 0.50000\tMoving Avg: 0.23720\n",
      "Episode 288 \tMax score: 0.00000\tMoving Avg: 0.23620\n",
      "Episode 289 \tMax score: 0.20000\tMoving Avg: 0.23720\n",
      "Episode 290 \tMax score: 0.20000\tMoving Avg: 0.23720\n",
      "Episode 291 \tMax score: 0.30000\tMoving Avg: 0.24020\n",
      "Episode 292 \tMax score: 0.60000\tMoving Avg: 0.24430\n",
      "Episode 293 \tMax score: 0.10000\tMoving Avg: 0.24330\n",
      "Episode 294 \tMax score: 0.20000\tMoving Avg: 0.24330\n",
      "Episode 295 \tMax score: 0.10000\tMoving Avg: 0.24030\n",
      "Episode 296 \tMax score: 0.20000\tMoving Avg: 0.24130\n",
      "Episode 297 \tMax score: 0.30000\tMoving Avg: 0.24130\n",
      "Episode 298 \tMax score: 0.00000\tMoving Avg: 0.24030\n",
      "Episode 299 \tMax score: 0.40000\tMoving Avg: 0.24330\n",
      "Episode 300 \tMax score: 0.30000\tMoving Avg: 0.24630\n",
      "Episode 301 \tMax score: 0.50000\tMoving Avg: 0.25030\n",
      "Episode 302 \tMax score: 0.10000\tMoving Avg: 0.25030\n",
      "Episode 303 \tMax score: 0.50000\tMoving Avg: 0.25430\n",
      "Episode 304 \tMax score: 0.20000\tMoving Avg: 0.25540\n",
      "Episode 305 \tMax score: 0.40000\tMoving Avg: 0.25450\n",
      "Episode 306 \tMax score: 0.40000\tMoving Avg: 0.25650\n",
      "Episode 307 \tMax score: 0.19000\tMoving Avg: 0.25450\n",
      "Episode 308 \tMax score: 0.20000\tMoving Avg: 0.25650\n",
      "Episode 309 \tMax score: 0.00000\tMoving Avg: 0.25350\n",
      "Episode 310 \tMax score: 0.20000\tMoving Avg: 0.25450\n",
      "Episode 311 \tMax score: 0.60000\tMoving Avg: 0.25850\n",
      "Episode 312 \tMax score: 0.19000\tMoving Avg: 0.25840\n",
      "Episode 313 \tMax score: 0.30000\tMoving Avg: 0.25940\n",
      "Episode 314 \tMax score: 0.20000\tMoving Avg: 0.25840\n",
      "Episode 315 \tMax score: 0.40000\tMoving Avg: 0.26140\n",
      "Episode 316 \tMax score: 0.10000\tMoving Avg: 0.26140\n",
      "Episode 317 \tMax score: 0.60000\tMoving Avg: 0.26440\n",
      "Episode 318 \tMax score: 0.19000\tMoving Avg: 0.26630\n",
      "Episode 319 \tMax score: 0.30000\tMoving Avg: 0.26830\n",
      "Episode 320 \tMax score: 0.30000\tMoving Avg: 0.27030\n",
      "Episode 321 \tMax score: 0.10000\tMoving Avg: 0.27030\n",
      "Episode 322 \tMax score: 0.20000\tMoving Avg: 0.27030\n",
      "Episode 323 \tMax score: 0.20000\tMoving Avg: 0.27030\n",
      "Episode 324 \tMax score: 0.10000\tMoving Avg: 0.26230\n",
      "Episode 325 \tMax score: 0.10000\tMoving Avg: 0.26030\n",
      "Episode 326 \tMax score: 0.60000\tMoving Avg: 0.26330\n",
      "Episode 327 \tMax score: 0.30000\tMoving Avg: 0.26430\n",
      "Episode 328 \tMax score: 0.20000\tMoving Avg: 0.26540\n",
      "Episode 329 \tMax score: 0.10000\tMoving Avg: 0.26240\n",
      "Episode 330 \tMax score: 0.40000\tMoving Avg: 0.26340\n",
      "Episode 331 \tMax score: 0.20000\tMoving Avg: 0.26340\n",
      "Episode 332 \tMax score: 0.40000\tMoving Avg: 0.26640\n",
      "Episode 333 \tMax score: 0.40000\tMoving Avg: 0.26940\n",
      "Episode 334 \tMax score: 0.20000\tMoving Avg: 0.27040\n",
      "Episode 335 \tMax score: 0.10000\tMoving Avg: 0.26740\n",
      "Episode 336 \tMax score: 0.10000\tMoving Avg: 0.26750\n",
      "Episode 337 \tMax score: 0.80000\tMoving Avg: 0.27450\n",
      "Episode 338 \tMax score: 0.10000\tMoving Avg: 0.27450\n",
      "Episode 339 \tMax score: 0.30000\tMoving Avg: 0.27350\n",
      "Episode 340 \tMax score: 0.20000\tMoving Avg: 0.27250\n",
      "Episode 341 \tMax score: 0.00000\tMoving Avg: 0.26950\n",
      "Episode 342 \tMax score: 0.10000\tMoving Avg: 0.26850\n",
      "Episode 343 \tMax score: 0.10000\tMoving Avg: 0.26850\n",
      "Episode 344 \tMax score: 0.10000\tMoving Avg: 0.26650\n",
      "Episode 345 \tMax score: 0.00000\tMoving Avg: 0.26250\n",
      "Episode 346 \tMax score: 0.10000\tMoving Avg: 0.25950\n",
      "Episode 347 \tMax score: 0.10000\tMoving Avg: 0.25950\n",
      "Episode 348 \tMax score: 0.10000\tMoving Avg: 0.25550\n",
      "Episode 349 \tMax score: 0.10000\tMoving Avg: 0.25550\n",
      "Episode 350 \tMax score: 0.40000\tMoving Avg: 0.25750\n",
      "Episode 351 \tMax score: 0.20000\tMoving Avg: 0.25850\n",
      "Episode 352 \tMax score: 0.20000\tMoving Avg: 0.25850\n",
      "Episode 353 \tMax score: 0.10000\tMoving Avg: 0.25950\n",
      "Episode 354 \tMax score: 0.70000\tMoving Avg: 0.26550\n",
      "Episode 355 \tMax score: 0.00000\tMoving Avg: 0.26350\n",
      "Episode 356 \tMax score: 0.10000\tMoving Avg: 0.26250\n",
      "Episode 357 \tMax score: 0.40000\tMoving Avg: 0.26050\n",
      "Episode 358 \tMax score: 0.29000\tMoving Avg: 0.26240\n",
      "Episode 359 \tMax score: 0.10000\tMoving Avg: 0.25940\n",
      "Episode 360 \tMax score: 0.20000\tMoving Avg: 0.25940\n",
      "Episode 361 \tMax score: 0.20000\tMoving Avg: 0.25940\n",
      "Episode 362 \tMax score: 0.10000\tMoving Avg: 0.25940\n",
      "Episode 363 \tMax score: 0.00000\tMoving Avg: 0.25640\n",
      "Episode 364 \tMax score: 0.10000\tMoving Avg: 0.25540\n",
      "Episode 365 \tMax score: 0.10000\tMoving Avg: 0.25040\n",
      "Episode 366 \tMax score: 0.50000\tMoving Avg: 0.25440\n",
      "Episode 367 \tMax score: 0.20000\tMoving Avg: 0.25040\n",
      "Episode 368 \tMax score: 0.10000\tMoving Avg: 0.24550\n",
      "Episode 369 \tMax score: 0.10000\tMoving Avg: 0.24450\n",
      "Episode 370 \tMax score: 0.19000\tMoving Avg: 0.24540\n",
      "Episode 371 \tMax score: 0.19000\tMoving Avg: 0.24230\n",
      "Episode 372 \tMax score: 0.29000\tMoving Avg: 0.24120\n",
      "Episode 373 \tMax score: 0.50000\tMoving Avg: 0.24520\n",
      "Episode 374 \tMax score: 0.20000\tMoving Avg: 0.24620\n",
      "Episode 375 \tMax score: 0.10000\tMoving Avg: 0.24330\n",
      "Episode 376 \tMax score: 0.10000\tMoving Avg: 0.24330\n",
      "Episode 377 \tMax score: 0.40000\tMoving Avg: 0.23830\n",
      "Episode 378 \tMax score: 0.10000\tMoving Avg: 0.23630\n",
      "Episode 379 \tMax score: 0.70000\tMoving Avg: 0.23830\n",
      "Episode 380 \tMax score: 0.10000\tMoving Avg: 0.23730\n",
      "Episode 381 \tMax score: 0.29000\tMoving Avg: 0.23920\n",
      "Episode 382 \tMax score: 0.19000\tMoving Avg: 0.24110\n",
      "Episode 383 \tMax score: 0.00000\tMoving Avg: 0.23410\n",
      "Episode 384 \tMax score: 0.20000\tMoving Avg: 0.23410\n",
      "Episode 385 \tMax score: 0.20000\tMoving Avg: 0.23210\n",
      "Episode 386 \tMax score: 0.20000\tMoving Avg: 0.23110\n",
      "Episode 387 \tMax score: 0.20000\tMoving Avg: 0.22810\n",
      "Episode 388 \tMax score: 0.10000\tMoving Avg: 0.22910\n",
      "Episode 389 \tMax score: 0.10000\tMoving Avg: 0.22810\n",
      "Episode 390 \tMax score: 0.00000\tMoving Avg: 0.22610\n",
      "Episode 391 \tMax score: 0.20000\tMoving Avg: 0.22510\n",
      "Episode 392 \tMax score: 0.20000\tMoving Avg: 0.22110\n",
      "Episode 393 \tMax score: 0.20000\tMoving Avg: 0.22210\n",
      "Episode 394 \tMax score: 0.19000\tMoving Avg: 0.22200\n",
      "Episode 395 \tMax score: 0.10000\tMoving Avg: 0.22200\n",
      "Episode 396 \tMax score: 0.40000\tMoving Avg: 0.22400\n",
      "Episode 397 \tMax score: 0.10000\tMoving Avg: 0.22200\n",
      "Episode 398 \tMax score: 0.10000\tMoving Avg: 0.22300\n",
      "Episode 399 \tMax score: 0.30000\tMoving Avg: 0.22200\n",
      "Episode 400 \tMax score: 0.20000\tMoving Avg: 0.22100\n",
      "Episode 401 \tMax score: 0.40000\tMoving Avg: 0.22000\n",
      "Episode 402 \tMax score: 0.10000\tMoving Avg: 0.22000\n",
      "Episode 403 \tMax score: 0.50000\tMoving Avg: 0.22000\n",
      "Episode 404 \tMax score: 0.19000\tMoving Avg: 0.21990\n",
      "Episode 405 \tMax score: 0.30000\tMoving Avg: 0.21890\n",
      "Episode 406 \tMax score: 0.20000\tMoving Avg: 0.21690\n",
      "Episode 407 \tMax score: 0.40000\tMoving Avg: 0.21900\n",
      "Episode 408 \tMax score: 0.30000\tMoving Avg: 0.22000\n",
      "Episode 409 \tMax score: 0.30000\tMoving Avg: 0.22300\n",
      "Episode 410 \tMax score: 0.30000\tMoving Avg: 0.22400\n",
      "Episode 411 \tMax score: 0.30000\tMoving Avg: 0.22100\n",
      "Episode 412 \tMax score: 0.10000\tMoving Avg: 0.22010\n",
      "Episode 413 \tMax score: 1.00000\tMoving Avg: 0.22710\n",
      "Episode 414 \tMax score: 0.30000\tMoving Avg: 0.22810\n",
      "Episode 415 \tMax score: 0.80000\tMoving Avg: 0.23210\n",
      "Episode 416 \tMax score: 0.20000\tMoving Avg: 0.23310\n",
      "Episode 417 \tMax score: 0.10000\tMoving Avg: 0.22810\n",
      "Episode 418 \tMax score: 0.10000\tMoving Avg: 0.22720\n",
      "Episode 419 \tMax score: 0.70000\tMoving Avg: 0.23120\n",
      "Episode 420 \tMax score: 0.20000\tMoving Avg: 0.23020\n",
      "Episode 421 \tMax score: 0.10000\tMoving Avg: 0.23020\n",
      "Episode 422 \tMax score: 0.20000\tMoving Avg: 0.23020\n",
      "Episode 423 \tMax score: 0.40000\tMoving Avg: 0.23220\n",
      "Episode 424 \tMax score: 0.70000\tMoving Avg: 0.23820\n",
      "Episode 425 \tMax score: 0.30000\tMoving Avg: 0.24020\n",
      "Episode 426 \tMax score: 0.40000\tMoving Avg: 0.23820\n",
      "Episode 427 \tMax score: 0.50000\tMoving Avg: 0.24020\n",
      "Episode 428 \tMax score: 0.10000\tMoving Avg: 0.23920\n",
      "Episode 429 \tMax score: 1.00000\tMoving Avg: 0.24820\n",
      "Episode 430 \tMax score: 0.50000\tMoving Avg: 0.24920\n",
      "Episode 431 \tMax score: 0.10000\tMoving Avg: 0.24820\n",
      "Episode 432 \tMax score: 0.10000\tMoving Avg: 0.24520\n",
      "Episode 433 \tMax score: 1.10000\tMoving Avg: 0.25220\n",
      "Episode 434 \tMax score: 0.40000\tMoving Avg: 0.25420\n",
      "Episode 435 \tMax score: 0.10000\tMoving Avg: 0.25420\n",
      "Episode 436 \tMax score: 0.50000\tMoving Avg: 0.25820\n",
      "Episode 437 \tMax score: 0.60000\tMoving Avg: 0.25620\n",
      "Episode 438 \tMax score: 0.40000\tMoving Avg: 0.25920\n",
      "Episode 439 \tMax score: 0.90000\tMoving Avg: 0.26520\n",
      "Episode 440 \tMax score: 0.70000\tMoving Avg: 0.27020\n",
      "Episode 441 \tMax score: 0.00000\tMoving Avg: 0.27020\n",
      "Episode 442 \tMax score: 0.20000\tMoving Avg: 0.27120\n",
      "Episode 443 \tMax score: 0.30000\tMoving Avg: 0.27320\n",
      "Episode 444 \tMax score: 0.40000\tMoving Avg: 0.27620\n",
      "Episode 445 \tMax score: 0.60000\tMoving Avg: 0.28220\n",
      "Episode 446 \tMax score: 0.30000\tMoving Avg: 0.28420\n",
      "Episode 447 \tMax score: 0.20000\tMoving Avg: 0.28520\n",
      "Episode 448 \tMax score: 0.10000\tMoving Avg: 0.28520\n",
      "Episode 449 \tMax score: 0.39000\tMoving Avg: 0.28810\n",
      "Episode 450 \tMax score: 0.10000\tMoving Avg: 0.28510\n",
      "Episode 451 \tMax score: 0.40000\tMoving Avg: 0.28710\n",
      "Episode 452 \tMax score: 0.40000\tMoving Avg: 0.28910\n",
      "Episode 453 \tMax score: 0.10000\tMoving Avg: 0.28910\n",
      "Episode 454 \tMax score: 0.10000\tMoving Avg: 0.28310\n",
      "Episode 455 \tMax score: 0.69000\tMoving Avg: 0.29000\n",
      "Episode 456 \tMax score: 0.20000\tMoving Avg: 0.29100\n",
      "Episode 457 \tMax score: 0.70000\tMoving Avg: 0.29400\n",
      "Episode 458 \tMax score: 0.80000\tMoving Avg: 0.29910\n",
      "Episode 459 \tMax score: 0.40000\tMoving Avg: 0.30210\n",
      "Episode 460 \tMax score: 0.10000\tMoving Avg: 0.30110\n",
      "Episode 461 \tMax score: 0.10000\tMoving Avg: 0.30010\n",
      "Episode 462 \tMax score: 0.50000\tMoving Avg: 0.30410\n",
      "Episode 463 \tMax score: 0.29000\tMoving Avg: 0.30700\n",
      "Episode 464 \tMax score: 0.80000\tMoving Avg: 0.31400\n",
      "Episode 465 \tMax score: 0.30000\tMoving Avg: 0.31600\n",
      "Episode 466 \tMax score: 0.50000\tMoving Avg: 0.31600\n",
      "Episode 467 \tMax score: 0.20000\tMoving Avg: 0.31600\n",
      "Episode 468 \tMax score: 0.40000\tMoving Avg: 0.31900\n",
      "Episode 469 \tMax score: 0.30000\tMoving Avg: 0.32100\n",
      "Episode 470 \tMax score: 0.20000\tMoving Avg: 0.32110\n",
      "Episode 471 \tMax score: 0.90000\tMoving Avg: 0.32820\n",
      "Episode 472 \tMax score: 0.30000\tMoving Avg: 0.32830\n",
      "Episode 473 \tMax score: 0.29000\tMoving Avg: 0.32620\n",
      "Episode 474 \tMax score: 0.10000\tMoving Avg: 0.32520\n",
      "Episode 475 \tMax score: 0.40000\tMoving Avg: 0.32820\n",
      "Episode 476 \tMax score: 0.39000\tMoving Avg: 0.33110\n",
      "Episode 477 \tMax score: 0.40000\tMoving Avg: 0.33110\n",
      "Episode 478 \tMax score: 0.70000\tMoving Avg: 0.33710\n",
      "Episode 479 \tMax score: 0.60000\tMoving Avg: 0.33610\n",
      "Episode 480 \tMax score: 0.70000\tMoving Avg: 0.34210\n",
      "Episode 481 \tMax score: 0.40000\tMoving Avg: 0.34320\n",
      "Episode 482 \tMax score: 0.30000\tMoving Avg: 0.34430\n",
      "Episode 483 \tMax score: 0.20000\tMoving Avg: 0.34630\n",
      "Episode 484 \tMax score: 0.10000\tMoving Avg: 0.34530\n",
      "Episode 485 \tMax score: 0.00000\tMoving Avg: 0.34330\n",
      "Episode 486 \tMax score: 0.60000\tMoving Avg: 0.34730\n",
      "Episode 487 \tMax score: 0.80000\tMoving Avg: 0.35330\n",
      "Episode 488 \tMax score: 0.30000\tMoving Avg: 0.35530\n",
      "Episode 489 \tMax score: 1.50000\tMoving Avg: 0.36930\n",
      "Episode 490 \tMax score: 0.10000\tMoving Avg: 0.37030\n",
      "Episode 491 \tMax score: 0.10000\tMoving Avg: 0.36930\n",
      "Episode 492 \tMax score: 0.20000\tMoving Avg: 0.36930\n",
      "Episode 493 \tMax score: 0.10000\tMoving Avg: 0.36830\n",
      "Episode 494 \tMax score: 0.70000\tMoving Avg: 0.37340\n",
      "Episode 495 \tMax score: 0.20000\tMoving Avg: 0.37440\n",
      "Episode 496 \tMax score: 0.59000\tMoving Avg: 0.37630\n",
      "Episode 497 \tMax score: 0.29000\tMoving Avg: 0.37820\n",
      "Episode 498 \tMax score: 0.70000\tMoving Avg: 0.38420\n",
      "Episode 499 \tMax score: 1.00000\tMoving Avg: 0.39120\n",
      "Episode 500 \tMax score: 0.20000\tMoving Avg: 0.39120\n",
      "Episode 501 \tMax score: 0.40000\tMoving Avg: 0.39120\n",
      "Episode 502 \tMax score: 0.40000\tMoving Avg: 0.39420\n",
      "Episode 503 \tMax score: 0.20000\tMoving Avg: 0.39120\n",
      "Episode 504 \tMax score: 0.60000\tMoving Avg: 0.39530\n",
      "Episode 505 \tMax score: 0.19000\tMoving Avg: 0.39420\n",
      "Episode 506 \tMax score: 0.00000\tMoving Avg: 0.39220\n",
      "Episode 507 \tMax score: 0.10000\tMoving Avg: 0.38920\n",
      "Episode 508 \tMax score: 0.30000\tMoving Avg: 0.38920\n",
      "Episode 509 \tMax score: 0.10000\tMoving Avg: 0.38720\n",
      "Episode 510 \tMax score: 0.30000\tMoving Avg: 0.38720\n",
      "Episode 511 \tMax score: 0.60000\tMoving Avg: 0.39020\n",
      "Episode 512 \tMax score: 1.10000\tMoving Avg: 0.40020\n",
      "Episode 513 \tMax score: 0.20000\tMoving Avg: 0.39220\n",
      "Episode 514 \tMax score: 0.60000\tMoving Avg: 0.39520\n",
      "Episode 515 \tMax score: 0.10000\tMoving Avg: 0.38820\n",
      "Episode 516 \tMax score: 0.70000\tMoving Avg: 0.39320\n",
      "Episode 517 \tMax score: 0.80000\tMoving Avg: 0.40020\n",
      "Episode 518 \tMax score: 0.20000\tMoving Avg: 0.40120\n",
      "Episode 519 \tMax score: 0.10000\tMoving Avg: 0.39520\n",
      "Episode 520 \tMax score: 0.29000\tMoving Avg: 0.39610\n",
      "Episode 521 \tMax score: 0.20000\tMoving Avg: 0.39710\n",
      "Episode 522 \tMax score: 0.20000\tMoving Avg: 0.39710\n",
      "Episode 523 \tMax score: 1.20000\tMoving Avg: 0.40510\n",
      "Episode 524 \tMax score: 0.39000\tMoving Avg: 0.40200\n",
      "Episode 525 \tMax score: 0.60000\tMoving Avg: 0.40500\n",
      "Episode 526 \tMax score: 0.40000\tMoving Avg: 0.40500\n",
      "Episode 527 \tMax score: 0.20000\tMoving Avg: 0.40200\n",
      "Episode 528 \tMax score: 0.90000\tMoving Avg: 0.41000\n",
      "Episode 529 \tMax score: 1.90000\tMoving Avg: 0.41900\n",
      "Episode 530 \tMax score: 0.20000\tMoving Avg: 0.41600\n",
      "Episode 531 \tMax score: 0.80000\tMoving Avg: 0.42300\n",
      "Episode 532 \tMax score: 0.29000\tMoving Avg: 0.42490\n",
      "Episode 533 \tMax score: 1.10000\tMoving Avg: 0.42490\n",
      "Episode 534 \tMax score: 1.20000\tMoving Avg: 0.43290\n",
      "Episode 535 \tMax score: 0.40000\tMoving Avg: 0.43590\n",
      "Episode 536 \tMax score: 0.20000\tMoving Avg: 0.43290\n",
      "Episode 537 \tMax score: 0.49000\tMoving Avg: 0.43180\n",
      "Episode 538 \tMax score: 0.20000\tMoving Avg: 0.42980\n",
      "Episode 539 \tMax score: 0.80000\tMoving Avg: 0.42880\n",
      "Episode 540 \tMax score: 0.10000\tMoving Avg: 0.42280\n",
      "Episode 541 \tMax score: 0.10000\tMoving Avg: 0.42380\n",
      "Episode 542 \tMax score: 0.20000\tMoving Avg: 0.42380\n",
      "Episode 543 \tMax score: 0.80000\tMoving Avg: 0.42880\n",
      "Episode 544 \tMax score: 0.10000\tMoving Avg: 0.42580\n",
      "Episode 545 \tMax score: 0.10000\tMoving Avg: 0.42080\n",
      "Episode 546 \tMax score: 1.20000\tMoving Avg: 0.42980\n",
      "Episode 547 \tMax score: 0.20000\tMoving Avg: 0.42980\n",
      "Episode 548 \tMax score: 0.10000\tMoving Avg: 0.42980\n",
      "Episode 549 \tMax score: 2.40000\tMoving Avg: 0.44990\n",
      "Episode 550 \tMax score: 0.50000\tMoving Avg: 0.45390\n",
      "Episode 551 \tMax score: 1.20000\tMoving Avg: 0.46190\n",
      "Episode 552 \tMax score: 0.30000\tMoving Avg: 0.46090\n",
      "Episode 553 \tMax score: 1.70000\tMoving Avg: 0.47690\n",
      "Episode 554 \tMax score: 0.30000\tMoving Avg: 0.47890\n",
      "Episode 555 \tMax score: 0.29000\tMoving Avg: 0.47490\n",
      "Episode 556 \tMax score: 0.90000\tMoving Avg: 0.48190\n",
      "Episode 557 \tMax score: 0.90000\tMoving Avg: 0.48390\n",
      "Episode 558 \tMax score: 0.19000\tMoving Avg: 0.47780\n",
      "Episode 559 \tMax score: 2.30000\tMoving Avg: 0.49680\n",
      "Episode 560 \tMax score: 1.20000\tMoving Avg: 0.50780\n",
      "\n",
      "Environment solved in 560 episodes.\tAverage score: 0.508\n"
     ]
    }
   ],
   "source": [
    "scores, avgs = ddpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzsvXmcHFW5uP+cXmbfssxkTyZ7wpYASQiEXXYUFFDgooKK3N8VRa96vaDXfQHxuiEqoiDqF0GvgiBEwpKwk0BWQgjZt0kmyWQms8/09HJ+f3RVdXV1VXfP0jOTmffhE6a76lTVqe7q9z3vdo7SWiMIgiAIAL6B7oAgCIIweBClIAiCIFiIUhAEQRAsRCkIgiAIFqIUBEEQBAtRCoIgCIKFKAVBEATBImdKQSk1SSm1Qim1WSm1SSn1eZc25yqlmpRS641/38hVfwRBEITMBHJ47gjwJa31WqVUKbBGKfWc1vpdR7tXtNbvz2E/BEEQhCzJmVLQWtcCtcbrFqXUZmAC4FQK3WL06NG6urq69x0UBEEYRqxZs+aI1royU7tcWgoWSqlq4GRglcvu05VSG4ADwJe11pvSnau6uprVq1f3eR8FQRCGMkqpPdm0y7lSUEqVAH8HvqC1bnbsXgtM0Vq3KqUuA/4BzHQ5xy3ALQCTJ0/OcY8FQRCGLznNPlJKBYkrhIe11o8592utm7XWrcbrpUBQKTXapd39WusFWusFlZUZrR9BEAShh+Qy+0gBDwCbtdY/8Wgz1miHUmqR0Z/6XPVJEARBSE8u3UdLgI8BG5VS641tXwUmA2it7wOuAf5DKRUBOoDrtMzlLQiCMGDkMvvoVUBlaHMvcG+u+iAIgiB0D6loFgRBECxEKQiCIAgWohQEQRAGES9uOUzN0fYBu74oBUEQhEHETb9/iwt/8vKAXV+UgiAIwiCjIxwdsGuLUhAEQRAsRCkIgiAIFqIUBEEQBAtRCoIgCIKFKAVBEATBQpSCIAjCIKczHGV/Y0e/XEuUgiAIwiDn3/+0hiV3Le+Xa4lSEARBGOS8tLWu364lSkEQBEGwEKUgCIJwjNAfy82IUhAEQThGiPXDEmSiFARBEI4RxFIQBEEQLMRSEARBECw0YikIgiAIBv3gPRKlIAiCcKwQk5iCIAiCYCKWgiAIwjAiU3aRWAqCIAjDiEwyvx8MBVEKgiAIgwUvoa+UsT+W+z6IUhAEQRjkGDpBUlIFQRCGE14xBWWYClK8JgiCMIzIJPNlmgtBEIRhhJfMN91HYikIgiAIiUCzxBQEQRCGD15CXxm2ghSvCYIgDCMy1imIUhAEQRDMoMIxXdGslJqklFqhlNqslNqklPq8SxullLpHKbVdKfW2UuqUXPVHEAThWKc/KpoDOTx3BPiS1nqtUqoUWKOUek5r/a6tzaXATOPfacCvjb+CIAjDDi9DwGdaCv2QfpQzS0FrXau1Xmu8bgE2AxMcza4E/qjjrAQqlFLjctUnQRCEwcywCTQrpaqBk4FVjl0TgH229zWkKg6UUrcopVYrpVbX1dXlqpuCIAiDmiGRkqqUKgH+DnxBa93s3O1ySMpda63v11ov0FovqKyszEU3BUEQBhzP4jUr0Jz7PuRUKSilgsQVwsNa68dcmtQAk2zvJwIHctknQRCEwcqQnuZCxWdwegDYrLX+iUezJ4GPG1lIi4EmrXVtrvokCIIwmPGcEM/42x+WQi6zj5YAHwM2KqXWG9u+CkwG0FrfBywFLgO2A+3AJ3LYH0EQhGMSc5bU/khKzZlS0Fq/invMwN5GA7fmqg+CIAjHEp6L7Bh/j/mYgiAIgpA9Ms2FIAjCMGB/YwdHWkOZG2YwFfpjmotcxhQEQRAEYMldywHYfdflPTreiiiIpSAIgjB88KxotpbjPIZTUgVBEITu0R+WQCZEKQiCIAwSPEMKQ2HqbEEQBKFvkZiCIAjCMMKrotknMQVBEIThhxSvCYIgCBaZDQGxFARBEIY9Q2bqbEEQBCF7Mi2iI4FmQRCE4YSn0JdAsyAIgmBguo/EUhAEQRhGZMo+OqZXXhMEQRC6R8aps/uhD6IUBEEQBgneE+LF/0pMQRAEQUAZDiSJKQiCIAwj7EL/zn9t5mfPbwXEUhAEQRiW2EX+b17ayc+e3+a5P1eIUhAEQRgkeGUXSfaRIAiCkILEFARBEIYRXkI/sRxn7vsgSkEQBGGQI4FmQRCEYUjG4jWxFARBEITE3EdiKQiCIAwbMk6d3Q99EKUgCIIwSPAMNMvU2YIgCMMPz1lSZepsQRAEwcQsXhNLQRAE4RinO8Hh/ggkZ0KUgiAIQg7pTsGZt/toCMQUlFIPKqUOK6Xe8dh/rlKqSSm13vj3jVz1RRAEYaDonqXgvl1l2N+XBHJ47oeAe4E/pmnzitb6/TnsgyAIwoDSJ1NTWBXNfXCuDOTMUtBavww05Or8giAIfc3Rti7ePdDcp+fsnssnQ53Csew+ypLTlVIblFL/Ukod79VIKXWLUmq1Ump1XV1df/ZPEIRhxAfufZXL7nllwK4/GNxHA6kU1gJTtNbzgF8A//BqqLW+X2u9QGu9oLKyst86KAjC8KLmaEefn7Mvg8OZKp77ggFTClrrZq11q/F6KRBUSo0eqP4IgiDkgr7IPvINh6mzlVJjlZFnpZRaZPSlfqD6IwiCkAu6Yyl4r6fQ/XP1lJxlHymlHgHOBUYrpWqAbwJBAK31fcA1wH8opSJAB3CdHgyVG4IgCH1Id6RaxgnxjuWUVK319Rn230s8ZVUQBGHI0hdjXXNCvOGQfSQIgjCk6VZMIdMiO73rSlaIUhAEQcghfVLRbMYU+iHSLEpBEAQhh3Qv+0gW2REEQRjS9ElMYTikpAqCIAwHujXJRaaYggSaBUEQjm36orZguExzIQiCMOTpi+wjaznOwTTNhVLqTKXUJ4zXlUqpqbnrliAIwsDRl26avokpxP8OmpiCUuqbwH8DdxibgsD/y1WnBEEQBpK+dNMcaxXN2VoKHwKuANoAtNYHgNJcdUoQBGEg6UvZ2ydzHzH4luPsMuYl0gBKqeLcdUkQBGFg6Vv3UTfa9tlVe062SuGvSqnfABVKqU8DzwO/zV23BEEQBo6+9N33SfZRP1Y0ZzUhntb6f5VSFwLNwGzgG1rr53LaM0EQhAGiL7N8upd95N7YTEntj0BzRqWglPIDy7TWFwCiCARBGPL0baC5GzEFrx2GqTAoUlK11lGgXSlVnvPeCIIgDDH6sqJ5UFgKBp3ARqXUcxgZSABa69ty0itBEIQBpC+zfPrkXOY5BtHKa08b/wRBEIY8fSl7Y7FuXTn9uQaLpaC1/oNSKg+YZWzaorUO565bgiAIA0dfyt7uxAG8lJG2/g6CmAKAUupcYBvwS+BXwFal1Nk57JcgCMKA0ds6Ba01P3t+KzVH25MEfSym+fGzWzjQ2JFyzPp9jTy8aq/H+YzjB4ulAPwYuEhrvQVAKTULeAQ4NVcdEwRBGCh6K3t3HmnjZ89v47l3D3HnVSda29fXNPKL5dtZv6+RP33qtKRjPvjL19L0J96jUcV5vexZZrItXguaCgFAa72V+PxHgiAIQw7drTiAy/HG0L4jHE2yFJo64l53c9Gc7M8H75tTxc1nTetdx7IgW0thtVLqAeBPxvsbgDW56ZIgCMLA0nvfvTXXdVL2UUtnBIDS/GxFb/+Tbc/+A7gVuI343b5MPLYgCIIw5Oht9pHdELDHAVo645ZCaUH3lILWyefMJdn2LAD8XGv9E7CqnPNz1itBEIQBpG/juS6WQneVApCY7CK3ZBtTeAEotL0vJD4pniAIwpCjr2ZJ1XhZCt0LyWqt+81SyFYpFGitW803xuui3HRJEARhYOnTWVJjqZZCfqD7KyH3k07IWim0KaVOMd8opRYAqYm2giAIfcCqnfU0tHUN2PW7E2h+bfsRywIwsQtw+5lMpTAY1k3wIlul8AXg/5RSryilXgYeBT6bu24JgjCcufb+lVx//8qB60CWUru+NcQNv1vFZ/+8zrONPfuovSuSsi2r7vRjoDmtUlBKLVRKjdVavwXMAf4CRIBngF390D9BEIYZpj9/y6GWgetDlu06wlEAtnn0VWvtmsnU3ZCFRltLcuaaTJbCbwDThjsd+CrxqS6OAvfnsF+CIAxT+mNx+kxkO5I3m6UrRnM7V7SbQYvBlJLq11o3GK+vBe7XWv8d+LtSan1uuyYIwnCkPxanz0S2XTDb+RzDa7vMt5/LHO13233EIHEfAX6llKk43gcst+0bvCV5giAcs/THpG+ZyLYLpnB3unZMF5gmWQGYAezBcI9eZFIKjwAvKaWeIJ5t9AqAUmoG0JTuQKXUg0qpw0qpdzz2K6XUPUqp7Uqpt+3ZTYIgDF/6Y3rojH3I1n1k/PUp9+1aJ1sKpjLobh2E1oMkpqC1/j7wJeAh4EyduBMf8LkM534IuCTN/kuBmca/W4BfZ+6uIAhDnUHgPcq6D5al4PDtuFkH8fPqlP1Z9Qf6rVAhowtIa52SF2bMkprpuJeVUtVpmlwJ/NFQNCuVUhVKqXFa69pM5xYE4dijNRQh4FMUBP2ebepbQxTmee/vL5wyu741xMjivBThnwg0J7c3V1vT6KSV18wAc7fdR3rwFa/lggnAPtv7GmObIAhDkBO+uYwP/OJVz/0HmzpZ9IMXWLmzvh975Y59dL+voZ1Tv/c8v31lZ0q7REzB+3i7VWAqg54E07s73XZPGUil4HaHrp+UUuoWpdRqpdTqurq6HHdLEIRcse1wq+e+xo4uojHNwaZQP/bIHbvM3tvQDsCK91Jljzny97IgIFmomcqgOzpB6/6NsgykUqgBJtneTwQOuDXUWt+vtV6gtV5QWVnZL50TBKF/Md0s4WgvV7jpA+xC2BT8fmc02bbPucsu/O1BZWtZzW74j8xzDAf30ZPAx40spMVAk8QTBGH4YgrSQaEUbII8qrNRCt6WQizptU46Z1Z9oX/rFHJWa6CUegQ4FxitlKoBvomxhKfW+j5gKXAZsB1oBz6Rq74IgjD4MeVkZBAk8du7EI2mUQrZZB+5KIVuu4/6MdCcM6Wgtb4+w35NfDU3QRCEhKUQGXhLwe5AimThPnLuSdQj9D7QbB4zHALNgiAIFoPLfZR4bfYrkE4pOIvXkhRB7+oUtPFffyFKQRCEQYE5Ig4PAveRvQempeBzUQoxr5iCx3kTlkI3+mJURQ+HQLMg9Dk/eXYL5/5oRb9e88YH3+Tzj3rPpy9kS1xSRhyWwuceWcfNf3irV2deubOe6tufpq4lu3TXJJdPzNtSiHhYCvbsopiL1dCdaS4Wff95ao529JtWEKUgDCnuWb6d3fXt/XrNl7bW8cR612xqoRtYlkI0WWD+c8MBnt98uFfnfvDVXQCs2dOQoWUcu8xOG1PwDDTbXsfsr3XKtkw0G6u1DYq5jwRBEPoLU2DmIqbQ3RhtUkzBVAouJzEzk7wqmrXWSemn0R7EFEwGy9TZgiAI/ULCUshdoDnrdRJIFeTpLIWUWVLtFc12pWDc2iAIm3giSkEQhEGBKTwj0YGXmG7uo+4Emq3YAQlFABA1/EY9shS6fUTPEKUgCMKgYFBlHyUVr8UFeXcCzW4prWCfJVXcR4IgCGnJZfGaGaTNVhQnu4/if93cR1mtp+BavJZlR2xIoFkQhGGFKUgjHqk53V2tzE5vAs2my8ct0BzxCjTbKpqjMbEUBGHA6Y0AOdboisT42uMbs87BH2ieftt93kvzG3OmpJpkmhNpT30b33pyE7GYJhyN8fV/vMOh5s7ka6Q5xYotibRXezOzP35/upRUONzcydce30g4GnOsp5Bob07DrbWm5mg733pyE22hCHc8tjHtvfUnOZv7SBAGEq37b2Q10Dyz6SAPr9pLayjCz687eaC7k5Fb/7yWy0+6PGW7qci9so86w1GCfu9x7C1/XMOWQy18dPFk9jV08KeVezjQ2MEDNy3Mql+f+H2iQM4+qDD742Yp2APNdzy2kRfeO8wFx41Jrk1w0USxGHzxLxt4c3cDje1d/COLOhexFAShF3RnauJjncR8OgPckV6SaT2FUIZYQ1NHGID8gN8aqffETRM/LvE6XYqsPdBsXr84L2DLPtLuSkFry02W/fcmMQVB6DHRY11CDjGyceclJsRzb9sZjqY9vi0UMa5lu67xt/ujbNssqUZ/3AYaZp99StFqXL8oz+9YpCf17D0KNIulIAg9p6cjRCE3ZCMEzTZegeZMlkJrVyTt8UDWs43aH58uQ6q7PVJWoFkpWjoTSslrltTE+bs/72l/xclEKQhDkuFoKQzm4Ho2StqKKUR6Zim4LdKjrL8qqU3Gvthem+4jtyU0rZRUoKUz7j6Kap20noLb9xI1Fs5xXisd3ZkvqTeIUhCGJMNQJwxqslEKmaa5yGQpmNgronv6GNgVgHk+t2fKvkaz6T6KaY1XRbN1/h50rL/WVBClIAxJurMw+lChv1bm6gnZjNCtmILHkDiTpWDSF1ai/Qym+8hNsSUCzSpRmBbTnhXN1vlt27L91vrLEBSlIHSbzbXNvF3TONDdSMtAZR8dau7kxS29m+Y5V7y2/Qg1R7s3rXhnOMoT6/f32jXlPHxPfRtv7KgH4msd7D7SZglir7mPsrYUbEpFpbyIU9vUwRPr97Ns00HP/q7Z08D2w61Wf9w+g5jNUjCJxpIzjryyj7pLf41zpE5B6DaX/vwVAHbflZprPlgYKEvhQ798jQNNnYPys7nhd6vID/jY8r1Lsz7mB0s388c39lBZms8Z00f3+NpOIXjOj14E4s/QdfevBODn180H0riPwt5K4Vcvbrde2y0F51Ngvr/6V69zoCle2LbhGxdRXhR0tNNc/et4vy49YaxxD6nXTcQvElohKV6gvesUuh1oFveRIPScgbIUTEEzWMl2tG1yoDF+P61GZk1PyS6mkD4l1ctaaWoPc/czW6z3bsebItscLNi/J9dnxbbJFPzpR/w2yyCGZ0Vz6nHZI+4jQegFA519NBxjGunIKiU1Q/Ga1zmcI2i3796Mt5jC2D7jaSQaS1E49lMk5itKvbbbvpjWrqutJfXZpZYiE/2VZi1KQRiSDHR2ZqZ5enLBYE5J7U7xmldMIVvrLxKLeX7/phAvzPNb27qiMSuYbGJXNJal4PKdmudLWkhH6yQLwtPC6OYqbGIpCEIvGHBLYRAL6IEgm6/D/Mjs2Ud2QeylWJznjsa05/dvfi/FeYlwajiqU9xqbrOkun2nrpZCTGdR0ayT2mdDfz1TEmgWhiQDPffRQFgKgzkl1Uug2QWildvv4s9Pdw6nAojHFLzaxv8W2SyFSDSWku5qPzpdnYJbvCEa0xkrmqM6cY1sBzD99USJUhCGJAPt0x9oS8XJQLuWvAR6klWQISDrNS+d896iMZ0SZzDVpTlYcLqPnJlN2iHk3a5j75+zLiFTRXMmpeGGTHMhCL2gt5ZCayhCfWtifQKtNfsa2tl1pC07/7hNwrWFIhxpzbzWgXkNk9qmjpSg676G9h4JhwHXUR7XDydVH6c2sq8REdOarkiM2qaOpDbO7zoSi6UoZdOIMj87u6WQyX0UtlkD0Zhmf2Pi+uZ1DtrWbYglwgXUt3XR4VJ0l1zHkLLbFZnmQhB6QW9/QOf+6EVO/d7z1vv/W13DWXev4Lz/fZHvPrU54/F2t8dFP32ZBbZzeWFe463dDbR3RTj9zuVJi69sPdTCWXev4P6Xd7oen05ZDLTl4nX5rkh6S+Gsu1ck9sc0//33tzn9zuWEIglB67w3Z/GYcx9AQTDZfWQ/HyQrqK0HW6z+3f3Meyy5a7m1eI95vu2HWz2v/9fVNSn9iMUSiiN795FYCoLQY3oblHOO7NfsOWq9fvC1Xa7HeLkE7CPLdKzdG7/G9sOtdBrujBc2H7L2m9XIK3fWZ3U+OwMd+Pa6vl0YZ7KAYhr+9U581Ta7heEcAERi2juDKZaa4dQVTbUs7F0xR/oxrXlpax0A9a1dKf1I9FNncS89cR9l1azXiFIQhiR9PTL2GqW5Lcrel9e3n8UMJHvIu7QMvKXgfv3OsHumkdc5TAUQsbnVUtxHUe3q67f3IxKLkR/wWe3TKYV029xqKqKxzGN6rRPPVLbfTX99haIUhCFJX2cfeZ3OSxH0VghrF6HmUyppX6IPma/V889D2/7fc7wu39GVsBQyfWQxra37sNcVpLqPYilBaSvQbGzvimorrhCOxlKune18RV5KIRsF59V/LyTQLAi9oK+zj7zO5uUG6IlSSMqNdxEAfkdVrnVdQy6lS0nV/RSk9MLTUohEM7ax9tvqD+zuH+dxkZi2agucH4k1lUYkRpFRqxBXCg5LweX6bt+pl/soGwVnXjJb99GQqGhWSl2ilNqilNqulLrdZf9NSqk6pdR649/NueyPMHzoa1Pb21JwF069rVNwS4M0Z2ZwCqeEqyRNoLnHAkXZ/t9zvD4Oe31Api7a5a99hO4UlvbiNXOXNc2FqVRiMZulkJ37yO0e3CyFmM4swJNTWNM2TRyTXbNek7M6BaWUH/glcCFQA7yllHpSa/2uo+lftNafzVU/hOFJ/8UUkq+plPfMmNmisCkF+3bLUkhun5X7qLfurF4dnSbQHPYW7il9sO0Pp3EfRWLa02oylWM4qikrsFkKKZ9Pal/cEgm83EeZ6MkAYigEmhcB27XWO7XWXcCjwJU5vJ4gWPSXqZ08XUHC799bIeyWUuvMtU/0IYvz9fLz6K07zuvySZZCpj4kKYXkz91OJBqz3EeJ62ujrRGTiMSsArZwNOZS65A+puDmxrK3y/R526fXjnhV5dk4d8dqbn7g29DUlLFtb8mlUpgA7LO9rzG2OblaKfW2UupvSqlJOeyPcAzT0hlOymnPRHeE8v8u20L17U+nb+Q4XfXtT/OH13cnXeein71kuVle2HyI6tuftvLZnVx//0qqb3+aJXctd72UtVCM3c3gMVtnNvears3j62qovv1pa43hrz2+kfnfeTb5+G4olbd2N1B9+9PsPtJmbfNybdljCnf9672057XLznCa7KPNtS38YGn8XC9treORN/dariezbSQWs+Y/CkdTYwBun5d9k6k0nBPpmcdm+koiUU1TR9h6nQ5/LMo3X/gN03dugsLC9CfuA3KpFNzsN+fd/xOo1lqfBDwP/MH1RErdopRarZRaXVdX18fdFI4FTvzWs3zsgVVZt++OELt3xfaMbdzO9sNn3kv68R9qTtQ2/P613QC8e6DZ9XxvGLUGXjUM9jV+Tcx7SgmKZlNhnabNb16KF8PVHI335eFVe2lsDzuOz3gJi8fW7gfgtR1HMh6fbuEcJ16WglOAP2er7QD45Yrt1rFm03BUJ1kKTkvIywJwXjPiYtLF5z5Kfy+1TZ3Wd+81Vfi0+ho+8O5LrLj/FqYereX/PngL5OWlP3EfkMu5j2oA+8h/InDA3kBrba/C+S3wQ7cTaa3vB+4HWLBgQX/FW4RBxqpdDVm37fPsI5dfeXtXNGW76eIxp03w2+bt19rb1510DhIjUe3ie3beW1Y+7CxkbzrF0Z3P07zlpJlDPesUslt32dmHdIHm1P6oFPdRPPsorhTc6hTcBhX2TaYyCEfc23XHXee2JvWnWzbztd/9V6I/yseaE5Zkfc7ekEul8BYwUyk1FdgPXAf8m72BUmqc1rrWeHsFkHn+AEHIgp7ohHRC2+t0zusoFKAtYRfw25ZpjOmk9+lwCzR7uY/M9+kUTjrLKVH/kLk/2WB1I4uq3Y5uWQqJ1+kCzU78PmW1Mf+GY4mU1C6XmIK7+yjVUnANNGdR0WzHaZVcsG0VX3vsu7QFC/j14mt4cu45xJRiYjD3VgLkUClorSNKqc8CywA/8KDWepNS6jvAaq31k8BtSqkrgAjQANyUq/4Iw4ueBHojMU3QIbRjMY3Pp7JKSQUsp6k5qg/6Ex7aqNZZ/eA07iP7xNz9zkBzqlXhdawbiQC2d5+6445TxodgPyKbQHMm7H1IV6fg1OA+lVAo9uwjc/4jd/eRW6ppqtXmNsrPxn1kx+4Ku3jr6/zqH3fRUlzGly/6LMtmnWHtG99PPpKcTp2ttV4KLHVs+4bt9R3AHbnsgzA86Um2TTSmsc2TFt+mNT5UVsVrkBpIs7uPMikq+7QHpnvCmfLqdp7urH/shqUUHHeZlILZA0shORc/c6A5E/b+2AO8mVxjfp9KWFlGtXE0pikI+vD7lDEtRvIx7tlH2DKGTDeUS7s0geYTa7fxqdX/YEtlNasnzGXthLnEImHyI12Ma67jllWPUVs6iv/55v/jxcPJcZ3+qmiW9RSEQU9Pfgw9tRTczhP0e/chxVBwVtD2YOoL+yybdkEdtSwCxzWyOG06peCVRpu8wE3mazjP5zUvlJ2eB5q9s4/c+mMeG9XaGt0H/T4CPuWakurqPkr6LmMp/bD3x366vEiYD25aweVbXuWcXWuNrS8BsK98DEXhTka1J1JNf7bkejqKS4k7TxL0V52CKAWhx2QbOO0tPRHwPbIUXDJOMl071VJI/jySBGuaRWLsn2N8mgaX/nm4j3qbkmpe2zllQ3cErxv2S3qmpHbHfWT7TJLcR1nEFMwmMZ24z6Bfkef30eXiPvKKKSiHe9CrojkQ6mR882HKO1u59fW/8v4tr9KaV8jfjz+Pn555A6FAPhduX8l1G5ZxoLyKmq5OuvxBfnLWR1k7YQ6nuPyuZDlOYdCjderIuLfsa2jnR8u2cPc1J1k+355MGRHTml+u2M6MqhIuPn4sz797iHcONHHx8WN56LXd/OCqE+kMR7n1z2utY9zSC3+wdDPf/9CJ2Qea01gK5vl/61gP4apfv87XLptrve8MR7ntkXWAu/sopjXffepd1u09SkVRHnPHlXr0Lu4b/8rf3uac2ZXWts/+eS13XX0SJfnxn7+ytbWzsaaJ5430znSCNxKN8ZW/v81nzp2BT8FDr+8G4gLzi39Zz23vm5nVNBeZsBekdUVjNHWE+dwj62hq70ruj+N73HSgmTxjRtS2UIRP/v4tAAI+HwG/YSmksZLQmtKudsKrtlHdfJiKwlJ0Z/z7unj9C1y2cTl/OOX9XLblNWbsVSz8AAAgAElEQVTX7aGt5kKmvfkSt23bZJ3i5eqT+fYFt7BjVCIh88/zL+XP8y9NinmYuP2u+slQEKUgdI+kZQoNf3tf8o0n3mHFljqunD+e980dE7+O7Rfz9X+8w3c/eELG80Rj8PDKPcyfXMHFx4/l5j+uBuDJ9QfYeaSNT589jZbOMC9uSdS9uCmfh1ft5fsfOtHzF3nZz19J249wLPnzAvj+0uQku3V7G3l1eyKn//UdR6yVvOyXtc/n88Cru6zt9qUlnbxzoJnH1u3nsXX7rW1PvV3Loqkj+fjp1UBCADkLsT750Fsp13Zj04FmHlu7n+2HW5MsnrV7j7Js0yH2NLRzx6VzXI91W5XMyfWLJvPoW3tp6YxY29btbeQrf3vbtb1bV83Cxx11rbyzP147sqB6BEV5Adq7oq7TbwMUdXVw3+M/4Ozd65L2h5/4Phw3lx+tjj9X5+1cA0DIHyD/4V/RlV/I89MX8tzMxRSFO3no1A+glXtZmFt/3ZRCH2dZeyJKQegW2eSe9wbTK+DzJbtTTP60ck9WSiEW04RjiapRE9P6aO+KpOzzski0Tl3z18R5DqfwtI+E0wlW+3KQSX52F0vBmfFin37aid/DlLMf4/N0H6XJ8PHAblHkBeKfdWc46inQ2tP03eTOq07kqQ0HOGqzCB55c29W/XFifrYfWTCRkyZWUFYYpLkjbA12ZtXtZnLjIaoL9vDjp/7Gkj0bqGxr5JeLP8zB0lEcLSwj7A/wFfYwraGGx44/j5emLeCcXWt4fvoinpu5mFsXVBEuq+BXL+3k7FmVvLy1+wW3PpfvTQLNwqDELthy8YyaQsX+o8hmbph4f5JH5WHDxWDHLFhq74rSbBt5gntMAeLKItt77bFSCCfm9Lf7qd0Czc7gbHtX/D7c+ujl3rOP0L3cR+nWLLDjZs1A4rsMRVKnpjZpC0VctztRCo46qqx7gpntdPlJ4wEoLwzQ1BEmGoPjD+3giT/8JwEdg8egOa+I16rn88i8i3l52qlJ5znnQ//OpFMn8qX/+RcATx53TuKeissJoMgL+Lhy3vgeKQU3JNAsDEp6u2ZAJsxz2ke4PVmZKhqLL8nY3JEsdIoMP3prp5ul4K58OsPRrH+QTmsjaRbQNLotFIkmCVE3vPabo343wZuNUjAVsNs8Pta1s7x/ex/Ma4QiUU+lkI2lAHHLsdERO3AjL+BLO0eW+X0E/QqiUaZ0NBDasZupe1/l/x7+BmF/kBuv/jpXzhnFXQ1lNBSVu54nEot5Pi9RrfFrjQLygz2bScjNUpBAszAo6cnasj05v817lHWg2dm3LjdLwXAfNXWEafZwHznN9FAk1uNF0+15+F5CxLyG2yRryVMrmEohWZCagtVNeXpNtpZkbRiftdu6AiY9WQjGtAJC4ZinUm3rys5S8CtFQ1tmS6Ew6E+vFCIxqlrqqf7pnfDXP/FD21xqW0ZP5vZLbmPdhDnMWTCVBlvcxkkkql1rFCAxzYVPKQoC3vGedLgGmsVSEAYjye6Bvj9/Yg3d7lskydNYayLRGM2OdMMCY+TW1BFOtRQMAermAurpD9LuPkonWEORxHTPdqHm5ppxWgrtlqWQel6vydbsMQW7+8hLoKb7DuxZQfZ2rYZSiMcU3I9PFw+xo1R2lkJB0EeTfY5BrZlXu5XPvvEXpjXsp75kBIv2vhPfN3s2y676NI815vHhk8Zya30loWB+yn24EY1pT8sqGtMEfAqfcrcUAj6VcaDjZuCJpSAMSuyKICeBZpf876wtBXseu62qtMXmtw74bUqh3T1InOICisR6nA5oX5g+XWgkZFMeXmmaXovRm24at+/DS3C5uY/C0ViKFWKSTkh22UbM9mamUghF0lgKoeyUgt+X3XNgJhJct/4ZblrzT0Z0tjCmtYEYijemnMiotiZ+tfgaLrnjFqZdcSHblm9j2bNbOen02YSWbbHOk86qi+/Xad1HMR3/XAucJfLEXVyRDMrQrf5HLAVhULD1UAs1R9s5f46RHpql++hgUyerdtVz5fzUJTQa2rp4fvMhPrIgdfkM83f/4Gu7OGdWJQG/LyUAunp3AwuqR/LE+v3MGVvG+n1HuXbh5KT+2LNT7G4ic5T94Ku7OH36qKTzmj9yp/A53BziuXeTp2POFruAj8RiPO9xnlAkRsDwmR1pTYyIozHN717ZyafOnOopFM1A8/L3DtPQ1sXI4sTEaV7uI3u/fMZgtiuqveMZab5r83M72NTJ4ZbE9OF76tute/vBUve5LrNJSYWE4vKpuIuozSlUtebDG5/niv3ribW0cM6utWwYO5NXp8xj1aQTeX3KSdRUjLWaX3jaYgDKC4MAKVZIJkshFInywCvu7qWYWZGuID+QainkBXwZYyk+1zoFsRSEQcBFP30ZgN13XQ44As1pBMX/rd7Hj5/byoXHjbFmozR56u0DfOOJTZwzq5IxZQVJ+8zzv7a9nkfe3MvHTq9OEYbX3PcG73z7Yj7/6Hpr20kTK5gwIrEAyY66xAIvdjdRhyFAW0IR1u9rTDqvNbeQQ5B+6a/r6Sn2H38shlUv4SQUiYKH//l7T2/mivnjPQvI7NbIrQ+v5ZFbFlvvPd1HSdlHcQkUicY8rZRfLN/Ov58z3Sp4s2New64QnLx3sMVzXzaYSmGsL8y8fZsYt3c7heFOpjTWMq1hP8VdHcyt2019+WhCMfjxmTdw3+JrCPuDruczLcYyQyk4M5syLXzz51V7Pe/36bdriWlNwO9ztRTcFIWTG8+o5vnNh5O29ZelkMtFdoQhiF0wpXtI2w3h4vTbQ0JQuu2zj9DMlFG3UZszSByOxtCG/KseVZS0z34du5A+0pr8ozbz8p1ugVqP1dPsXLfQfdHAhrbECNTuyilw+JrjMYXU+yzq6qCytYFQfWOKcvTFopSE2plzeBcfXbeUC7etpK62PqmNs/bAup5NkSgr0BxL68550CPw2uURcDXZ8M2LrNe3njc9Zf+i6pHWoMOVSIQJjbVcu2EZy37yUX790H/zjeW/5b9e+RNXbH6ZBfs3kx/p4vaLP8t/3PUEZ3zmIX6x5Hr++4qTKHQRyoA1G65pKRw1vqfXbz8fyGwp2L9XJy2hCG1d0XhMwUUBfO3y49KeG+DkySPYfdflfOfK47n6lImAxBSEQYrdOsiUdw/Q3BFhXLnXvvRKwcTNbdLcmXysfdKziqI8MFwX4K0UnKf1iilkg9uIEJKFR1NH4nVB0J80wg+FY5RG2pjYdIiR7U3Mq93KRVtXsnjfRoKxKLHf5XPGlR+nastefFoTiEU5Z9caKtuSrZ3IP/zw5+nwoQ/BDTcQjo6ksvUop+3byNm71vJu1TTa8gqIRY6H9YVw4onWseFoarGfHS+XRyb/u10BBnypQtIrbdMfizK58SDMn89fN8WnjNgxcSY/ueLfeS5aQczno7Z0NAtr3mXD2JmEgvmcbVilhUE/N581jbttcQI7QYel0GC4j8z1LuzPwLc+cBzf+ue7jnvO/Iwol5jCf14wi8kjizyOsB1r/P346dVsn97K39fWSExBGJwkZR+leUrNVEw3IWPucwp2r3O6Fa85g8Q+pSyFVVGU7DJIdh9FKckPWEHQpOt4xBSyIc/DJWBXCmZKZWXrUW54+1XO2PgKY1obKOrqJJaXT0lnK8WdCbfX7opx/G7hh9hXMYb/OfAai/76W2YVlFAY7qS5oIQ1E+ayu2IcReEQj8y/mIqOVs6reZtbylvg7rvhhz/k4pIyPtDqsiTov4AfA6NGcVewhD/NPo/YGf9JU3sX+ZEulI7RGUx27XkFob1cVNZnY1tTwrleBUC+4TYb2d7E4r0bKQ21ccnW11lY8y4lXR0wYgQ/+9Dneal4EiXnLMHn81FjKwh7c9IJtnPFr2XGZ7xcbqZScFoKZn2M/Tnv6aSPilRLwct6SEdiJTuxFIRBiH1QmO4ZNa0BN6VgtyKcZGspuBWemT+aEUV5nm3bwxFGl+S5KgWvmEI22H/ogWiEhTXvUtVaz6LX93L+uuWEAnnkLZvMb9oUZ+9aR2EkxJ6KsWyqmkbM56cy2kFXaTlPV86lM5jP+nGz2D1ivOXbufoXX2fN8re4c6dGaU1M+VyT2VdPm8ct378MtmyBp56i5uXV/KmtlH3lY3ltyjxGdjRT1drAbH8nd503ER59lAnPPMPtBx+Clx6ivXIMbzfEp2xeP342S2cvobirg2kN+zk0+tPw/uNSruuVr29iF6oBRwS1srWBDz/2d3iriNd/81sKInHhfLh4BK9Un8yWyil84eE7+effdrGjro3Li/I8p+4ALHeROeL3ins53UcNbV0olYhd2K2fnk762BmOplgKPp97RpIT+zXNz6+fDAVRCkJ2mCuQZes+6rmlkHout+s4zxtfPSv+2vyhu7VtD0WZPKqIPQ3taA2l+QErZTViuY+SR76ZBmj54RAnrXiSry5/gymNtSzeu5HyUHzEH/b5WT3xOOqKR3BKVwsz6ut4es6ZLL3ko6zwjbImSasszWdsWQEb9ze5XqMDP3UTp6F37UKnEVJWDGH2bJg9m9eX7OH3/3jH2r8/r4D95VXsL82HGy+AG2/kml++StmK57hJ1VK9fztvNUNbXhHvf+8Vvr0vcSz/9QL88naYNw8mT4YzzoCzz6ZwxxZOqt1KRyCfQ6WjaM4vtqRaXiQMq1Yxu243N675Jx++5xXOKamyTjmu5QgVna3g99OSX8pXLr2NgnAXy2cs5EjxCAC+MGUKPrUbiH+36ZSC6aryG24qr+/OaSk0d0bw+5Tr2hI9nfKxrSuaZCVB/GPJxlKwT8Fu6lFxHwkDjj0TJRyLke/zZ13RnJ2l0POYQqpS0J6Wgv06HeEo+QEfJfkBWjojlBTYlIJH8ZobvliUwnCIqzYt54uvPMyIznh2TcgfZOnsJTw/4zR2jJrIrpETCAXi/bl2wST+snofAHPGlqJtGTmhcDSt2yoUiaatc/DCy7WT9N1qWD5jEeNOm8zI4jx+sXw7AN8/75OMbzlCY0FJfF2Azm18+Oh7sHkzPP88/OIXAHzA+GfSHsynOb+YhqJypjYcgB+HWEZ88fna086i6L0ttOQXU1s6mvcqq9n/qc/w2S9czcKv/svzPkxhnVkpGJaCW06nDVMpBP0+ivL8tHdF4+d1rJcA9Gp+eJ+jH4oeWApGp8R9NMQ42NRJ0K8YVZJvbYvGNNsOtzBnbFnG49u7Ihxs6mRaZYm1rakjTEtnmIkjUgNXWw+1MHV0MUG/j2hM88aOejSaM6aPTloi8mBTJ0qRlBoai2m2HGphlC3fvbUzwuv76ym1pSSaD2k4GuP1HfUcP76M0SX5bDnYYuXON7V38e6BZo4bn7hHuxVR1xKiKxqjoyvC+IpC9jYkAsTmdBNRl0DmhprkEXU4GrNSBNPFFNq7ogT9PsoLg7R0RigtCFBrnGpzbTPTq4qpbXTPNprQdJib33qcYDTCB999Me7vBjZXVrPqR/fzpR1+/DpGc0GJ6/Hr9h21XvsdwqK5M0JRmoyW5zcf4qjLNA/mIjFeeKVWNndGeGlrHadPG5W0YIz9swoF89k1Ml5ncrSonL9Wn0DF2dPxKVg8pYL2J5/myDtb2N6heHZb3OU0tqWeqrYGyjrbmNJYy6PzLuITn7uaHz3wAs/OXMzHP305X7dZLgCfnDk1USzhgRnPKC8Muubwm5gC1/n5OrHvLy8M0t4VxWfzyO06kojtdEcl+H0q7aCiJzGFbNbQ7ktEKfQTi+98ASAp9e6nz23l3hXbef6L5zCjyl2QmNz68FpWbKljxw8usx7oS3/2MgeaOlPS+Q40dnDRT1/mpjOq+dYVx7NyZz0ffWAVAH/45CLOmZVYcOXqX7/O/sYONn37YooNgf+7V3fyg6XvcffVJ1nt/rxqLz9+biunThlhbTOf/WfeOcjnHlnH+XOq+Mb7j+Pin71stbln+XbuWb6dv9yymLrWEOfPqbIshbqWEAu//7znPZuFVG5plf/ccCDpfSSq+cUL2wAYV54cIHVaFaZSqDnaYd0zwL0rtnPviu2WS2Fm3R7KQ62MbG/m+g3PcM7OtUR8fhSaFdMXsqlqGmsnzOHNSSfwndNOpa1mo3Wui44bw7OOQrWth1qt124j2YNpUl8feXOf0XeV9HmMLS9IUqRO0imMGx98k59fN98SYm1dUR5ft5+RxXmuKZdv7T7KW7vjdRZfvmgWzx2pYkMkH4JAmizLT9x4Ob/cPBqAfH+qQHSm57rRaqTKlhYE0loBVqDZiBlcMW88TxrPysmTK1i3tzHlmPLCILVNnfhVwmmzx5a9dvz4MpbMGMVr2+tTjgU4a+ZoXtl2xLq+maXlfA4B5k2q6H6g2SeWwrDhzd3x0dXhls6MSsFchKWlMxxPuQQONLkLkXqjInblzvhDXGcrsjnsEDz7G+Oj3VW76q2qZbOo650DTSnt7K4YU5g0Gtv21Ld5FvQs3VjLH97Yw7+dNtka9a3Ykjql8IXHjbGqh02lYF5n3sRyy0IYV17AqJI8a8GUrmiM1lCEceUFXHjcGOt8eX5fipsq6Fdxwa81xx/awfSN65hdtxulNS9OW8DM+r18YvWTTG5KCPX2YAFPHnc2Pz3zBvZUjEtxKZTkJ6yTD84fz93XzGOWMa3y/1w+l+89nVzRayr2C48bwxXzxvO5RxKLuMybVMGGfanCC6C8MM+qr3ji1iX88Jn3UpSCfXnPTEVYdS0hy1J4aUsd4ahmfEUBR9u7XEemE0cU0tQR5nBLiMaOMOPLC5KeQ3vf50+q4OGbT0s6vqwwtZjMbZuTLuOZKQz6renPnWz45kX86Y3dSdt+8pF5fPeDJ+BT8Qyx2f/zjOf1fT6Vkmn0x08u4uTJI/j9TYsIRaJo4NKfvWL9HgDu/bdTOOuHy2nujFBWELc6rjplAl836hE2fusi8gN+WkMRq9p8wzcuQqM5++4VKVO4Q/LjZVrst543w/sD6kNEKQwCsvFh5wf8hKMRmjsillLwwhS6ph+2xRbQdXsAAdcZKO3C1Jx6ocNlgreQNUWy93TC5qpZdS2htPGG+ZMqLKVg+r1NoRV3ccWVQkVRHuPLCy2lEI7GaO6McPz48qQf9qiSPI60dlEaakOjGN98mCsff4Li5qPc8c46Tjy0I953f5D8aJibVz8BwK5xU/nByZ8w8voLqZkym7qI9wi1OD8hqCqK8pJSVKvKUkeMZr7+iKIgH5g3nruXvce+hg4+ungy3/vgiVTf/jQAa79+Iad89znbcYk+jC7NTwmqQ1xBmmme4WjMdblHk6aOsJXya2Zk/e+H53Htb1a6fj9lBUF8StHcESYUjjFrbGmSUqgqTbhH/3HrEuu1aeGMKErtr9s9ODGfgfyA31OJlBcGrUpl89kM+H2UF6YfmZvX9xuT2NkZbbh78wI+6zstLUgWm8V58T41d0YoMp6DmVWljDCEeWlB/PwjA4nfbbnxOeQH/eCmFGxOq4KgP31xXx8jSqEf8Ar2mV97i4egtlMQ9NEachekzoXfzTbmJrsi8CpOss/9Yj6QdbaKX3N0ap/V0hxJmiP6UCTmmmYKiWUpC4N+Dke83SR209pUHmZMId8WoMsP+JLex9dOCDN/RBCWLeNja59iasMBTq/fSWFTA5OP1uIzkvpiykc0GORgYQX/uOkr/D46hrfHzWRC02EmNR3mQNloJpx6Aq/vbLDOX6B8gLcrxqeUFbB0xiWLXUa2Tp+3OcVyvmOqC6drxX6cZfE46AwnK4Wg3+c5p1FTRzglwD2iKI/ywqDrs1IQ9OH3xfd1RqKMLctP2u/lGgn6fYSjUUtQ2slGKZiztxYEfWnbmwHk7nhazPP5lEoSxuAem8h3BIoDfp/1nZvfYzYuMfBeGW8gEaXQD7hl2dhJV0VqYv7I3dpGYjqpKMhsY1oKzZ1h8vw+CoLJrhR7BspRl2mJ9zUkTGRTKdirWq2pnI3zdHZFPe/VVDoFQV9SJa8Te2aGGZA2fej2eywlzOSDu5hZd5CGonJ8h2o5dd1LfPO7P4H2Vr4LdAby2D39BDaOmc7S2WfQUFhGZ7CA4EeuIb+qkvte3c2NZ1Sz4Y09ANRUjLUmTTvOYY2l6zPE8+GtgKXjh+6c+wkSPm8Ts6rXKUycSsIej83zuwvIuKUY3x6OavIyKAWnpVpeGPQUvPkBP0V5iibDUnC288qsMSeBc5t2oruWQrr2ecbn2h2lUFZgUwoOGe0WvihwUXymMkl8j9mto+CVcTaQukKUQj+QlNERiVo/dO2y3wtzBOaa9x+OWiMkexvzwTKzbIry/UnH2183tqfGCuy+6vo07qNOQ+C0hCLWdAFOzOMLg37PylhI/jGZloKvsZGPrn2aq17bw+W1dUyvr2Fy0yF8OsZ/mY3vhSuAprETKXj87yx5fD91xSO44rSp/G1NTdI1/m3kaEaXFIBSFHj4p82J3zIpMZNoVCcClj6nUki9hjNYarqTnErAeS57XwJ+n6srxT6vUTgaS1FAdpodlkJh0E9B0FvwFgR9FOUFqG3qoDOSWpzlZSmY+frOFE3ITinYr5+ufcCyFLLXCgn3Ueo+t/46LYWkfd0MIreG3H/7A2k/iFLoB5yCuKo0Ydo793uRl0YphCIxSj2uBwmlUJwfyEoptLg8qG5THDtjCgA1R90zYQ4ZAe6A31vI5ke6qF6xlK8uf4bJTQeZ+0g9fOEIVx89yjVa01ZSzt7CEbwzdgYbz30/0WnTeXnLIUa0N3PGCRP5U63ifbdczccuPIGGV56hKxxlVEmquyLPJky9Jkwz/cAjivKo9Qjo24nEtHXOFPdRvpv7yF14ZHI7tNpcgV7uI7vSNd1HXjgtBVOBpbMUygoDHGmNB6KdQjCdpQBx5elUtOZIPRvyA36KXSwvk6AVU8j6lJQXxs/nd7EU3Nw7bpaCSZ6h1ENZTgnu9Vvo6dQafYEohR4Si2k6wlErpTEa0ymjulAkSigSS0rvqznawciiPNq6opYgrmsJ0RaKJKVHRqIxwlGNRpMf8Fs/tkPNnTS2dyUFMk03kNmHQ81xV09rZ4RoLO5rLysMUpIfsARcayiS1K/9jR2EIlE6uqJZLXsI8R9evFYiIajs+d1mznZ+OERxTS2zmg8zs20dt65Zx9i6/Yxsb2JG/T4iPj/BWJTirg78OsaJ/iB7K8ZSN3YiEy49n7cbwnwvbw5zrrqIPxupmR+YN57JIwt5LBgPFDedOpEX19RwxagKIC7cOsJRRhcn+7whWZh6K4X4d1GRpVKIxrQl3JyCxDn6N/tgxzzEra0du3IO+txHzXUtXUwcESUa07R1RTMqheaOsLW2sSmMygrdRUNeIK5QzQFFdy2FrmiMkvwgneFEvKq7loLb6N3E/Fy7s/aAGfT12SqaTdxSet0UX+L7i9+nl7vuWGDYK4W6lhDvHWzmYw+8yVOfO5MTJrgv1G0nEo3x4d+8wYZ9jcwZW8a7tfEMmFVffR8HGjsYXZLPkdYQn/rD6pR876t+9XrK+f62pobH1tbw+GeWMG9SXKhdc98bVmro5JFFVjHYz1/Yxs9f2JbkfghFYryxo57rf7uSr10211pgZueRNqZ/dSkAS2aMoiQ/wOs76rn14bU8vbHWOr6qNJ/1+xpd0/VMyjpbqT56gKJwJ1e8+zKhQJCXX3uEpflF+PMKubX1KFVtDfie1VyMYlR7I3OaailraUiZybPLF2BX5SSOFJSydM6ZxJQipnzUF5Vz4Q2X8IFdFcR8th9e/CPheNvoekZlCcFA4jMwXURmyl9hnh/acA1sFgb9jDYsiLEuueQAEyriazPMHVvK5tpmxpTlW8o2P5Dqo68oCiYFLO24uW/MYkGz8ND0dpiWQnGey0IywOiSPEoLguw60obPp5IKDE2u/+3KpPczqkqYP6kiZf0ISKw7MXVkEbuOtDHGCByPdDmvif2aTiVQ7LLeAsDc8WXsPNJGfsDHpJGFSdOWO7N57GSKsTgxlfzoktTBgBf278353Tnfu/UJYNaYUvbUtzN3bCnPvXsoqUg1U387wlEqioJJ1rq4jwYQe/HUK9uOZKUUXtl+xCqCMRUCwCcfeotNBxLvC4N+zplVyUtb6/jShbMYU1bA39bW8OauBkoLAnzpwllUlRXwXm0z9yzfzs4jrZZSsP+ATd9+XsDHHZfO4VBziPte2mHtD4VjvF0Tb//9pZspyQ8weWRRUt/GlBZw05Jqlm06xDObDlrbbzt/BucXdXLnr/7FmNZ6ThtXxMxghPF7tqIOH6Lo8EGCB2qs6l2T5rwiyrqSXUVdpWXEfH5CkRiNwUJGLjqFw758Huwoo654BPvLqqgtHcWixXOZd/xkvvb4O9x51YkUB/184S/xhWyWXHo6SwsCvLGjnm87pis2R7ynTK7g1vOm09wZoTgvwDefjE+rfPulczhjerxI6uLjx/LAq7s4e+Zo7r7mJFo6I3z3qXcZURTko6dPYXRxPr/9+AIumFvFyOI8IjFNY3sX//mXDUC80OmPn1zEwuqRfPT0KUysKDTmalJGFXQnLZ1hjraHKc7zs2TGaF4wFkVxDmTHlRfyx08uIqo1335yE7vr27nouDGcOWM0586uTGprCr3lXz7XslD++dkzKS8MsnJXPbPHlDJxRKElzBdOHcndV59ERVGQvQ3tKfUQt543nfPnjGFGZQmf/8s6XtxSxxXzxvOBeeN5a3cD97+8E4CHPrGQ13fUc8rkeHHijWdUM7a8kAkVBSileGlLHQ+9vhuAjyyYxA+Wvmf195WvnMfWQy0caOrkshPGcu7syhSX0I+uOYnrFk5i0sgifnTNPN7c1cDZs0ZzoLHTGvmv+PK5hKMxdhxupTg/QFlhkLGOdF4zkPvU586krjXEpBHx59xU8mfPquTOq05MKrK0s+LL56asQ21PSfX7FA/etIB2Y/dewpEAABGgSURBVDZdt/oh01KYO66Mn147D4CfXjuf9XsbOWP6KE6cWMEFc6tSjnPj4U+fxs66Nk6ZXMEbO+s5d3YV+xra01pDuWZYK4XuBKPsHPJwJ9gVAsCUUUX8/qaFHGzuZLwx8tzT0MabuxqoKs3npiVTAVg0dST3LN9upXM6+zWzqoRth1u5YG4Vn1gylX0N7UlKoTOSPG/OwuoR/PqjpzLn6/GR/8XHj+GbF02n9N2NXLTtDUa2NXFiSy1XBxso+N3bUF/PX5w3M2ECjB9P49w5/HXUXA6XjKRm9AR0OMK6CbM5UFZFIBqhpKudss42mkaMZsNdH4z3vytKXkcXpeWFlAK/NnLuTb68YDqXnTCOM6aPZuroYgBLKRQE/MwZW8b4ikJLKfz24wuYPaaUh9+MZwldcNwYAn4fI4vz+PjpUyyl8JEFkyy32lcvm8snllRTVVZgLft5wdwqJo4oSiocAzhrZlwwd3RF+U/iSqG8MMjMMfFIjSko7fUGzhXjIOFycXuqzjaqyO8p3sbu+nYCfh8XHDc6pZ05Ch1TVmBd48SJ8YHKZNviQeZINOj38RFjgR83S+Djp1db51kyfTQvbqmjtCDAhceNYdvh+NxLI4qCTBlVzJRRxdZxVaUFfGzxFOv9QeOZ18Rdaub04/lBH5NGFjFpZGrf7BTlBazPeUZViSVs7VO0mM/CrDGlKcdbn4+hNO2DN7vgLgj6uX7RZM/jzWvYSVgK8fdmEadnHwylcNKEcmuKmpL8AGfOjH+f9uLJTJwyeYT1fJlT2JhW6kAxrJVCpnVSvWjMIjAM8SClz6cshQCJB9Du5zW3mX5aZ1D3/DlVbDvcaqVmOjNOQuH4nDUF4U4mNh1mSWwHBfet4uuvvUawrZWLnz1C+afXQyjE/cYxncF8CuadCFdeCYsWccOKIxwsHcWdNyxi0fGToDL+A95/oInv3PMqEHdj2TOSIv4AjYVlNBaWJQXoCvP8FOZ5P9jlhUF8PuX6AzWFYoktmDiyOBgXiIa0tZv09oBcmc0N4feplDmh7ELPDbsrJJsqWydmcNptWm4Ts+9eccRM7pF0uPnz7f560z9u9rO7vnzntVpDvetvT/BakKc3lNkshWwwA81ecZdjnaF5V1nizM3PtFiI/Th74MyLEhdfqflDLOpohfXrYedOgjt38u0XX2PqnnGw5QRCxeW8f/PblIXaqOho4QN785jy7j7mPVEP92jKmppYdTA+6VhMKYK/K+GESIyvNjUkXevj/gBtwQL0jJnwmc/A2Wdz84pDvBvOY8LxM/i/W8+y2r62Kz6aL5gxDSorrO125VVVmu85z05PioXcMEdhdvPZbG9mO3n9dANpAqrZ4POp+Peqss8zt2NOFpiuGNHsu9fn1Ruh59Zn+zazX6YPvztKwVRmphVrnjfbIq2+orspn9lgr1PICqNdYZosqGOZnN6VUuoS4OeAH/id1voux/584I/AqUA9cK3Wencu+2Sn0bF6VzapoQCNbWEqioLEdOo6vykcPQorV8I//wmbNnHle9u4uLklPof8VxPNPhIsIP/NEDyqGQHcaztFtLCQMQSpGzsJpk5GzZzJy5sbaA4WEvH5ubS6hD2HW1gZLWFfxVjOuHAR1117Ngt/vY7Gjgj/71OnWabtoX2vcmB/E3OK3QOsTkGRpBTKUt0CbkHXTKQTRm5C0RzJmYI0l9l6+QGfZ+1CJkxh2+KyToSJKXi8JjfrjdDLdKzZL6dS6IkT1bxWf1sKuUjVLAj6yQ/4slYKZspvLhTUYCBnSkEp5Qd+CVwI1ABvKaWe1Frbo4efAo5qrWcopa4Dfghcm6s+ObEsBa1RpF+f1nlcRVGQSEzT0NzOhOY6ZtTvIy8SZnpDDaPam6hqbeC03++CG43CqZISmDeP5jPPZtmuFkITJ3PzjRfA1KkwdSof+sNGppTn8ZtLq3l77Va++NgmmvOLaSoo4eHPncs1973BcePKWPr5+Oj+O99cZq0DMPa6+Tz65j7eMCbAm33CbKiqsqSn3cw1X3sJ5lSlkPihVJW6+dGDSRPuZUNapeAiZMyRnCm8sh7R9YD8NIVbmTAtw3Tuo0zTIPdG6GWybsx+mYV53akPMDG7bcZucuHOGQjKC4NZu4/M4kBRCt1nEbBda70TQCn1KHAlYFcKVwLfMl7/DbhXKaV0TyPA3SS0bQdfeekhLtq6kklNB2kcPR7unwWjR0N5OVRUxP+VlEBBARQWQkEBC59ZyRfffJaR9QepaG4gL5YsBDoC+dQXlbNv1glU/eetcOqpsGQJFBVxqKaJr9/7KnPGlnLz1Wdbx5QVBjnapWHsWA5Oge2jEwuwmELKPi1FftBvKQUzpuCFXciZr70EX2lB9yyF0oJAt5WC8xp23NwRprDrj6mD8wPpK2bTUZKN+8hUCjlYXDGzpZCsFHp6n5Co6u2vOf5zjRnnygbTMk5X2Xwsk0ulMAHYZ3tfA5zm1UZrHVFKNQGjgCN93ptly6j91GeSXB0Lm+u5oKOFlrxCnpx7LiWxLqZsO0Dphi2UdLRS3NFKXjRV2H4a2D9hGu/MOoXd0Tx2jxjHO2NmEPP52DJ6Ch3BfFCKD84fz6nXnZx0rJlbX+LI5y4vDPLS1jou/MlLKULFHIHaRzLxqtK4MP7Rs1uSJrQzhUNZQTz32X4tc3ToFUh1jpbsSqHSJaukogeCxW1EplRcwDiXL7Rjjk7zcjhCyzSNQjqyOc6cB8lp7ZhVz72ZIM1UnmYhmhNzrGX203yu0tUJmJjfi/lsjTQKviI9WQ5uEFJeGMx60GE+oiUulepDgVwqBben2/mpZ9MGpdQtwC0Akyd7p5ulpayMpqkzrSIwgCO+mbx4yQ3sn3k8vkCQjnDqCC/Y1UleqJO8rk4C4S7yukJEAkHOu+IsdEzz9oYDFOYF+NzxY/jHuv189qTxvL6jnmgsxm3vm5lyvtljSrnt/Blc60ibu+G0ySmumoXVI8kL+BhbVsCXL5rF+08ab+2//ZI5/Oudg0RimmgshkJx1SkTWLWrgRtOi6cSPvSJhSzdWJtUiHTNqRNp74py+Ynjkq7/9/84g821ySm1EE9XvPnMqZQWBDlrZiUfOnkCFx8/hnV7G+kMR/n02dN4cUtd0spqTu776Kn4fYpRJXmu1wBYettZvL6jPsl98ugti9lrW+zkc+fPBA3XGimYJj/+8DzXBU16wm3vm5m2cCsdU0cX88ULZ/Ghk+Orlf3i+pNTBO4Prz6Jh17fxaLqkUnbf/zh+Ty8ag8nZlEn44Xfp/jqZXM4Z1YVm2ubU+7jzqtO4uFVe1hoXHtUcR5fvmgWlzmeBTcuPG4M/9850/n3s6fF7+Oak3jotd0scNxHrnjk04s50NiRuWEP+f/Ome457buT/7poDsX5gaTf41BC5cpTo5Q6HfiW1vpi4/0dAFrrO21tlhlt3lBKBYCDQGU699GCBQv06tWrc9JnQRCEoYpSao3WekGmdrmMlLwFzFRKTVVK5QHXAU862jwJ3Gi8vgZY3l/xBEEQBCGVnLmPjBjBZ4FlxFNSH9Rab1JKfQdYrbV+EngA+JNSajvQQFxxCIIgCANETusUtNZLgaWObd+wve4EPpzLPgiCIAjZMzQTbQVBEIQeIUpBEARBsBClIAiCIFiIUhAEQRAsRCkIgiAIFjkrXssVSqk6YE8PDx9NLqbQGBwM1XuT+zr2GKr3dqzf1xStdWWmRsecUugNSqnV2VT0HYsM1XuT+zr2GKr3NlTvy4m4jwRBEAQLUQqCIAiCxXBTCvdnbnLMMlTvTe7r2GOo3ttQva8khlVMQRAEQUjPcLMUBEEQhDQMG6WglLpEKbVFKbVdKXX7QPenOyilHlRKHVZKvWPbNlIp9ZxSapvxd4SxXSml7jHu822l1CkD1/P0KKUmKaVWKKU2K6U2KaU+b2wfCvdWoJR6Uym1wbi3bxvbpyqlVhn39hdjWnmUUvnG++3G/uqB7H8mlFJ+pdQ6pdRTxvuhcl+7lVIblVLrlVKrjW3H/PPYHYaFUlBK+YFfApcCxwHXK6WOG9hedYuHgEsc224HXtBazwReMN5D/B5nGv9uAX7dT33sCRHgS1rrucBi4FbjexkK9xYCztdazwPmA5copRYDPwR+atzbUeBTRvtPAUe11jOAnxrtBjOfBzbb3g+V+wI4T2s935Z+OhSex+zRWg/5f8DpwDLb+zuAOwa6X928h2rgHdv7LcA44/U4YIvx+jfA9W7tBvs/4AngwqF2b0ARsJb4GuVHgICx3Xouia87crrxOmC0UwPdd4/7mUhcOJ4PPEV8Wd1j/r6MPu4GRju2DannMdO/YWEpABOAfbb3Nca2Y5kxWutaAONvlbH9mLxXw61wMrCKIXJvhotlPXAYeA7YATRqrc3FwO39t+7N2N8EjOrfHmfNz4CvAOaixqMYGvcF8TXin1VKrTHWhoch8jxmS04X2RlEKJdtQzXt6pi7V6VUCfB34Ata62al3G4h3tRl26C9N611FJivlKoAHgfmujUz/h4T96aUej9wWGu9Ril1rrnZpekxdV82lmitDyilqoDnlFLvpWl7rN1bVgwXS6EGmGR7PxE4MEB96SsOKaXGARh/Dxvbj6l7VUoFiSuEh7XWjxmbh8S9mWitG4EXicdNKpRS5mDM3n/r3oz95cSXqB1sLAGuUErtBh4l7kL6Gcf+fQGgtT5g/D1MXJEvYog9j5kYLkrhLWCmkSGRR3wt6CcHuE+95UngRuP1jcT98eb2jxuZEYuBJtP0HWyouEnwALBZa/0T266hcG+VhoWAUqoQuIB4YHYFcI3RzHlv5j1fAyzXhqN6MKG1vkNrPVFrXU38d7Rca30Dx/h9ASilipVSpeZr4CLgHYbA89gtBjqo0V//gMuArcT9ul8b6P50s++PALVAmPjo5FPE/bIvANuMvyONtop4ptUOYCOwYKD7n+a+ziRubr8NrDf+Xfb/t3c/oXFVURzHv7+4SCOxahW6skLoQhGDoeBKRHCjFKQ0gSAt4rIgBIQsWum/gAiC4MaFBaFWGlNoF1m0KIJRi0WNYNugWXWRdlcIWFJtoTQ9Lu6Zl3GYhKkZU5j5feAxM+fN+3NheGfunTfndkjbBoGL2bbfgcMZHwBmgSvAaaA345vy9ZVcP/Cg29BCG18BznZKu7INl3P5o3ad6ITP4/0s/kezmZlVumX4yMzMWuCkYGZmFScFMzOrOCmYmVnFScHMzCpOCtYVJC1n5cvasmalXEn7JL3VhuMuSHpyvfsx2yi+JdW6gqS/IqL/ARx3gXL/+mKL7/8e2Ao8HxF3JT0MzACfR8Sn/9uJmiX3FKyr5Tf5D3Pug1lJ2zN+VNJ4Ph+TNJ81809lbIuk6Yz9LGkw409I+ibnGjhGXX0cSXvzGJckHcuS7s3cBPbl82eAe04ItlGcFKxb9DUMH43WrVuKiBeBTyh1fBrtB4YiYpCVi/UEcDFj7wFfZPwI8GNEDFHKIGwDkPQsMEopuPYCsAzsWeVcJ4DxLJPRA9yRtFnSGUmrbWPWFt1SJdXsdl6Mm5mqe/y4yfo5YFLSNDCdsZeAYYCImMkewqPAy8DujJ+T9Ge+/1VgB/BrVoHtY6WwWqPrwHHgMPBlxoaBr4C3gck1W2q2Dk4KZv8ud9zsR7adlIv9G8AhSc+xdtnkZvsQcCIiDrR4Th8B85RijlASyGvAnRa3N/tPPHxkVoZ1ao8/1a+Q1AM8FRHfUSaWeQzoB86Twz85r8BiRCw1xF8HHs9dfQuMZJ3+2m8STzc51iPAckT8DXwAvA+l1wFcAMba1mqzJtxTsG7Rl7Og1XwdEbXbUnsl/UL5kvRmw3YPASdzaEiUeYhvSDoKHJc0B9xipbTyBDAl6TfgB+AaQETMSzpImdWrh1Lx9h3gat2x3qX0BGoTu3xGmQsZSbsoQ0cjrJSoNms735JqXe1+bxk163QePjIzs4p7CmZmVnFPwczMKk4KZmZWcVIwM7OKk4KZmVWcFMzMrOKkYGZmlX8AP4aAfRJf8U0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc3fbae6940>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores, label='DDPG')\n",
    "plt.plot(np.arange(len(scores)), avgs, c='r', label='Running AVG')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode №')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Future ideas**\n",
    "- Algorithm is very sensitive to hyperparameters. Furter tuning could lead to different results.\n",
    "- Different weight initialization and different activation functions affect model performance. Leaky_Relu and Normal distribution prooved to be useless. Could try other(xaviernormal, xavieruniform, kaiminguniform,kaimingnormal).\n",
    "- Algorithms other than DDPG could be used for solving the environment. Also could try to change Actor-Critic architecture, making a single Neural Net, which share input layers and first hidden layer and splitting after.\n",
    "- Prioritized Experience Replay could be implemented to further enhance the performance of the agent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
